{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxX1koauU9CA"
      },
      "source": [
        "### Execution Environment\n",
        "\n",
        "This notebook is designed to run both **locally** and in **Google Colab**.\n",
        "\n",
        "When executed in Google Colab, the notebook automatically uses the project\n",
        "directory located at:\n",
        "\n",
        "`/content/drive/MyDrive/pads`\n",
        "\n",
        "When executed locally, the notebook assumes it is started from the cloned\n",
        "project root directory (`pads/`) and automatically uses that path as the\n",
        "project root. Alternatively, the project root can be specified explicitly via\n",
        "the `PADS_ROOT` environment variable.\n",
        "\n",
        "No manual path changes are required when these conventions are followed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mm2k_bgAKAD",
        "outputId": "d308e416-69a9-4eeb-8a30-ede0479bff01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m152.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m133.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"Installing required packages...\")\n",
        "!pip install torch torchvision torchaudio transformers datasets scikit-learn pandas numpy matplotlib seaborn tqdm wfdb onnx onnxruntime onnxruntime-tools onnxscript -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "anTGw_6s8QiU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import essential libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import requests\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import struct\n",
        "import itertools\n",
        "import inspect\n",
        "import re\n",
        "import io\n",
        "import ast\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "import gc\n",
        "import glob\n",
        "\n",
        "\n",
        "# Import PyTorch and related libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.ao.quantization as aoq\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, balanced_accuracy_score, accuracy_score, precision_score, f1_score, recall_score\n",
        "\n",
        "from transformers import PretrainedConfig, PreTrainedModel\n",
        "\n",
        "import onnxruntime as ort\n",
        "import onnx\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsInhU7agd-G",
        "outputId": "89a6835b-569a-472a-caa4-f44adb42653d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b05f1ccf",
        "outputId": "dde64599-e4cb-4793-9c04-fc519fab63e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory structure and constants defined successfully!\n",
            "BASE_DIR: /content/drive/MyDrive/pads\n",
            "DATA_DIR: /content/drive/MyDrive/pads/data\n",
            "MODELS_DIR: /content/drive/MyDrive/pads/models\n",
            "RESULTS_DIR: /content/drive/MyDrive/pads/results\n",
            "MOVEMENT_DIR: /content/drive/MyDrive/pads/preprocessed/movement\n",
            "PATIENTS_DIR: /content/drive/MyDrive/pads/patients\n",
            "QUESTIONNAIRE_DIR: /content/drive/MyDrive/pads/questionnaire\n",
            "LABELS_CSV: /content/drive/MyDrive/pads/preprocessed/file_list.csv\n"
          ]
        }
      ],
      "source": [
        "# --- Paths / project root (Colab + local) ---\n",
        "def _detect_base_dir() -> Path:\n",
        "    \"\"\"\n",
        "    Priority:\n",
        "      1) Use PADS_ROOT env var if set (works for local + Colab).\n",
        "      2) If running in Colab and Drive-mounted path exists -> use it.\n",
        "      3) Otherwise use the current working directory (assume repo root).\n",
        "    \"\"\"\n",
        "    env_root = os.environ.get(\"PADS_ROOT\")\n",
        "    if env_root:\n",
        "        return Path(env_root).expanduser().resolve()\n",
        "\n",
        "    colab_drive_root = Path(\"/content/drive/MyDrive/pads\")\n",
        "    if colab_drive_root.exists():\n",
        "        return colab_drive_root.resolve()\n",
        "\n",
        "    return Path.cwd().resolve()\n",
        "\n",
        "BASE_DIR = _detect_base_dir()\n",
        "\n",
        "# Define subdirectories\n",
        "DATA_DIR = BASE_DIR / \"data\"\n",
        "MODELS_DIR = BASE_DIR / \"models\"\n",
        "RESULTS_DIR = BASE_DIR / \"results\"\n",
        "MOVEMENT_DIR = BASE_DIR / \"preprocessed\" / \"movement\"\n",
        "PATIENTS_DIR = BASE_DIR / \"patients\"\n",
        "QUESTIONNAIRE_DIR = BASE_DIR / \"questionnaire\"\n",
        "\n",
        "# Define specific file paths\n",
        "LABELS_CSV = BASE_DIR / \"preprocessed\" / \"file_list.csv\"\n",
        "\n",
        "# (Optional) Create output directories if they don't exist\n",
        "for directory in [MODELS_DIR, RESULTS_DIR]:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# (Optional) Sanity checks for required inputs\n",
        "required = {\n",
        "    \"MOVEMENT_DIR\": MOVEMENT_DIR,\n",
        "    \"LABELS_CSV\": LABELS_CSV,\n",
        "    \"PATIENTS_DIR\": PATIENTS_DIR,\n",
        "    \"QUESTIONNAIRE_DIR\": QUESTIONNAIRE_DIR,\n",
        "}\n",
        "missing = [name for name, p in required.items() if not p.exists()]\n",
        "if missing:\n",
        "    raise FileNotFoundError(\n",
        "        \"Missing required data paths under BASE_DIR:\\n\"\n",
        "        + \"\\n\".join([f\"- {name}: {required[name]}\" for name in missing])\n",
        "        + \"\\n\\nIf running locally, start Jupyter from the repo root (pads/) \"\n",
        "          \"or set PADS_ROOT to that path.\"\n",
        "    )\n",
        "\n",
        "print(\"Directory structure and constants defined successfully!\")\n",
        "print(f\"BASE_DIR: {BASE_DIR}\")\n",
        "print(f\"DATA_DIR: {DATA_DIR}\")\n",
        "print(f\"MODELS_DIR: {MODELS_DIR}\")\n",
        "print(f\"RESULTS_DIR: {RESULTS_DIR}\")\n",
        "print(f\"MOVEMENT_DIR: {MOVEMENT_DIR}\")\n",
        "print(f\"PATIENTS_DIR: {PATIENTS_DIR}\")\n",
        "print(f\"QUESTIONNAIRE_DIR: {QUESTIONNAIRE_DIR}\")\n",
        "print(f\"LABELS_CSV: {LABELS_CSV}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6cDN-YYCNty",
        "outputId": "26a70f61-68fe-41d1-ff27-e7db2bc66010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if6fb7Kr_pqA",
        "outputId": "76d8fd0b-06c0-4cd3-ac62-3870c77ce408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required packages...\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Download PADS dataset\n",
        "#def download_pads_dataset():\n",
        "#    \"\"\"Download PADS dataset from PhysioNet\"\"\"\n",
        "#    dataset_url = \"https://physionet.org/files/parkinsons-disease-smartwatch/1.0.0/\"\n",
        "\n",
        "#    print(\"Downloading PADS dataset...\")\n",
        "#    print(\"Note: This is a large dataset (~1.4GB). Please be patient.\")\n",
        "\n",
        "#    # Use wget to download the entire dataset\n",
        "#    download_cmd = f\"wget -r -N -c -np -P {DATA_DIR} {dataset_url}\"\n",
        "\n",
        "#    try:\n",
        "#        os.system(download_cmd)\n",
        "#        print(\"Dataset download completed!\")\n",
        "\n",
        "        # Check if download was successful\n",
        "#        expected_path = DATA_DIR / \"physionet.org\" / \"files\" / \"parkinsons-disease-smartwatch\" / \"1.0.0\"\n",
        "#        if expected_path.exists():\n",
        "#            print(f\"Dataset found at: {expected_path}\")\n",
        "#            return expected_path\n",
        "#        else:\n",
        "#            print(\"Download may not be complete. Checking alternative paths...\")\n",
        "#            return None\n",
        "\n",
        "#    except Exception as e:\n",
        "#        print(f\"Error downloading dataset: {e}\")\n",
        "#        print(\"Please manually download from: https://physionet.org/content/parkinsons-disease-smartwatch/1.0.0/\")\n",
        "#        return None\n",
        "\n",
        "# Alternative: Direct file download using requests\n",
        "#def download_file_direct(url, filepath):\n",
        "#    \"\"\"Download a single file with progress bar\"\"\"\n",
        "#    response = requests.get(url, stream=True)\n",
        "#    total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "#    with open(filepath, 'wb') as file, tqdm(\n",
        "#        desc=filepath.name,\n",
        "#        total=total_size,\n",
        "#        unit='B',\n",
        "#        unit_scale=True,\n",
        "#        unit_divisor=1024,\n",
        "#    ) as pbar:\n",
        "#        for chunk in response.iter_content(chunk_size=8192):\n",
        "#            size = file.write(chunk)\n",
        "#            pbar.update(size)\n",
        "#\n",
        "# Try to download the dataset\n",
        "#dataset_path = download_pads_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d951bf8a"
      },
      "source": [
        "## Framework 1: (Modality-based)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f52e1f6"
      },
      "source": [
        "### Data Cleaning and Preparation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkgx6wBp_0HL",
        "outputId": "5d64e6fe-155e-43f4-d2c9-fc7e82a54d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 469 .bin files\n",
            "Dimensions: 976 × 132\n",
            "Loaded 469 patients\n",
            "Conditions: {\"Parkinson's\": 276, 'Healthy': 79, 'Other Movement Disorders': 60, 'Essential Tremor': 28, 'Atypical Parkinsonism': 15, 'Multiple Sclerosis': 11}\n",
            "Processed 469 questionnaires\n"
          ]
        }
      ],
      "source": [
        "class CleanDataPipeline:\n",
        "    def __init__(self, movement_dir: Path, patients_dir: Path, questionnaire_dir: Path):\n",
        "        self.preprocessed_path = Path(movement_dir)\n",
        "        self.patients_path = Path(patients_dir)\n",
        "        self.questionnaire_path = Path(questionnaire_dir)\n",
        "\n",
        "        self._analyze_bin_structure()\n",
        "        self.patient_metadata = self._load_patient_metadata()\n",
        "        self.questionnaire_data = self._load_questionnaire_data()\n",
        "\n",
        "    def _analyze_bin_structure(self):\n",
        "        bin_files = list(self.preprocessed_path.glob(\"*.bin\"))\n",
        "        if len(bin_files) == 0:\n",
        "            raise ValueError(\"No .bin files found!\")\n",
        "\n",
        "        sample_file = bin_files[0]\n",
        "        file_size = sample_file.stat().st_size\n",
        "        num_values = file_size // 4\n",
        "        print(f\"Found {len(bin_files)} .bin files\")\n",
        "\n",
        "        if num_values == 128832:\n",
        "            self.actual_timesteps = 976\n",
        "            self.actual_channels = 132\n",
        "        else:\n",
        "            self.actual_channels = 132\n",
        "            self.actual_timesteps = num_values // 132\n",
        "\n",
        "        print(f\"Dimensions: {self.actual_timesteps} × {self.actual_channels}\")\n",
        "\n",
        "    def load_bin_file_raw(self, patient_id, target_length=950):\n",
        "        patient_id_str = f\"{patient_id:03d}_ml.bin\"\n",
        "        bin_file = self.preprocessed_path / patient_id_str\n",
        "\n",
        "        if not bin_file.exists():\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            with open(bin_file, 'rb') as f:\n",
        "                data = np.frombuffer(f.read(), dtype=np.float32)\n",
        "\n",
        "                if len(data) == self.actual_channels * self.actual_timesteps:\n",
        "                    data = data.reshape(self.actual_timesteps, self.actual_channels)\n",
        "                    data = self._adjust_to_target_length(data, target_length)\n",
        "                    return data\n",
        "                else:\n",
        "                    return None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _adjust_to_target_length(self, data, target_length):\n",
        "        current_length = data.shape[0]\n",
        "\n",
        "        if current_length == target_length:\n",
        "            return data\n",
        "        elif current_length > target_length:\n",
        "            excess = current_length - target_length\n",
        "            start_trim = excess // 2\n",
        "            end_trim = start_trim + target_length\n",
        "            return data[start_trim:end_trim]\n",
        "        else:\n",
        "            padding_needed = target_length - current_length\n",
        "            padding_before = padding_needed // 2\n",
        "            padding_after = padding_needed - padding_before\n",
        "            return np.pad(data, ((padding_before, padding_after), (0, 0)), 'constant', constant_values=0)\n",
        "\n",
        "    def _load_patient_metadata(self):\n",
        "        patients = []\n",
        "        patient_files = list(self.patients_path.glob(\"patient_*.json\"))\n",
        "\n",
        "        for patient_file in sorted(patient_files):\n",
        "            try:\n",
        "                with open(patient_file, 'r') as f:\n",
        "                    patient_data = json.load(f)\n",
        "                patients.append(patient_data)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        df = pd.DataFrame(patients)\n",
        "        print(f\"Loaded {len(df)} patients\")\n",
        "        if len(df) > 0:\n",
        "            print(f\"Conditions: {df['condition'].value_counts().to_dict()}\")\n",
        "        return df\n",
        "\n",
        "    def _load_questionnaire_data(self):\n",
        "        questionnaire_data = {}\n",
        "        quest_files = list(self.questionnaire_path.glob(\"questionnaire_response_*.json\"))\n",
        "\n",
        "        successful = 0\n",
        "        for quest_file in quest_files:\n",
        "            try:\n",
        "                patient_id = quest_file.stem.split('_')[-1]\n",
        "                with open(quest_file, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                features = self._extract_questionnaire_features(data)\n",
        "                if len(features) >= 10:\n",
        "                    questionnaire_data[patient_id] = features\n",
        "                    successful += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        print(f\"Processed {successful} questionnaires\")\n",
        "        return questionnaire_data\n",
        "\n",
        "    def _extract_questionnaire_features(self, questionnaire_data):\n",
        "        features = {}\n",
        "        if 'item' not in questionnaire_data:\n",
        "            return features\n",
        "\n",
        "        for item in questionnaire_data['item']:\n",
        "            if 'link_id' not in item or 'answer' not in item:\n",
        "                continue\n",
        "\n",
        "            link_id = item['link_id']\n",
        "            answer = item['answer']\n",
        "\n",
        "            if isinstance(answer, bool):\n",
        "                features[f'q_{link_id}'] = 1 if answer else 0\n",
        "            elif isinstance(answer, (int, float)):\n",
        "                features[f'q_{link_id}'] = float(answer)\n",
        "            elif isinstance(answer, str):\n",
        "                mapping = {\n",
        "                    'never': 0, 'no': 0, 'false': 0, 'not at all': 0,\n",
        "                    'rarely': 1, 'slight': 1, 'mild': 1,\n",
        "                    'sometimes': 2, 'moderate': 2, 'occasionally': 2,\n",
        "                    'often': 3, 'severe': 3, 'frequently': 3,\n",
        "                    'always': 4, 'very severe': 4, 'extreme': 4\n",
        "                }\n",
        "                answer_clean = answer.lower().strip()\n",
        "                features[f'q_{link_id}'] = mapping.get(answer_clean, abs(hash(answer_clean)) % 5)\n",
        "            else:\n",
        "                features[f'q_{link_id}'] = 0\n",
        "\n",
        "        return features\n",
        "\n",
        "# Initialize pipeline\n",
        "data_pipeline = CleanDataPipeline(\n",
        "    movement_dir=MOVEMENT_DIR,\n",
        "    patients_dir=PATIENTS_DIR,\n",
        "    questionnaire_dir=QUESTIONNAIRE_DIR\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "784834d7"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "760098ae"
      },
      "outputs": [],
      "source": [
        "class OnTheFlyAugmentation:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def apply_axis_rotation(self, data, max_angle=15):\n",
        "        augmented_data = data.copy()\n",
        "        for start_idx in range(0, data.shape[1], 6):\n",
        "            if start_idx + 5 < data.shape[1]:\n",
        "                angle = np.random.uniform(-max_angle, max_angle)\n",
        "                rotation_matrix = self._get_rotation_matrix_3d(angle)\n",
        "\n",
        "                # Rotate accelerometer data\n",
        "                acc_data = data[:, start_idx:start_idx+3]\n",
        "                rotated_acc = (rotation_matrix @ acc_data.T).T\n",
        "                augmented_data[:, start_idx:start_idx+3] = rotated_acc\n",
        "\n",
        "                # Rotate gyroscope data\n",
        "                gyro_data = data[:, start_idx+3:start_idx+6]\n",
        "                rotated_gyro = (rotation_matrix @ gyro_data.T).T\n",
        "                augmented_data[:, start_idx+3:start_idx+6] = rotated_gyro\n",
        "\n",
        "        return augmented_data\n",
        "\n",
        "    def _get_rotation_matrix_3d(self, angle_deg):\n",
        "        angle_rad = np.radians(angle_deg)\n",
        "        axis = np.random.choice(['x', 'y', 'z'])\n",
        "        cos_a, sin_a = np.cos(angle_rad), np.sin(angle_rad)\n",
        "\n",
        "        if axis == 'x':\n",
        "            return np.array([[1, 0, 0], [0, cos_a, -sin_a], [0, sin_a, cos_a]])\n",
        "        elif axis == 'y':\n",
        "            return np.array([[cos_a, 0, sin_a], [0, 1, 0], [-sin_a, 0, cos_a]])\n",
        "        else:\n",
        "            return np.array([[cos_a, -sin_a, 0], [sin_a, cos_a, 0], [0, 0, 1]])\n",
        "\n",
        "    def apply_time_warping(self, data, sigma=0.2, knot=4):\n",
        "        orig_steps = np.arange(data.shape[0])\n",
        "        random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2,))\n",
        "        random_warps = np.abs(random_warps)\n",
        "\n",
        "        time_warp = np.cumsum(random_warps)\n",
        "        time_warp = time_warp / time_warp[-1] * (data.shape[0] - 1)\n",
        "        warp_steps = np.linspace(0, data.shape[0] - 1, num=knot+2)\n",
        "\n",
        "        warped_data = np.zeros_like(data)\n",
        "        for i in range(data.shape[1]):\n",
        "            try:\n",
        "                warped_indices = np.interp(orig_steps, warp_steps, time_warp)\n",
        "                warped_indices = np.clip(warped_indices, 0, data.shape[0] - 1)\n",
        "                warped_data[:, i] = np.interp(warped_indices, orig_steps, data[:, i])\n",
        "            except:\n",
        "                warped_data[:, i] = data[:, i]\n",
        "\n",
        "        return warped_data\n",
        "\n",
        "    def apply_random_augmentation(self, data):\n",
        "        augmented = data.copy()\n",
        "\n",
        "        if np.random.random() < 0.6:\n",
        "            augmented = self.apply_axis_rotation(augmented)\n",
        "\n",
        "        if np.random.random() < 0.4:\n",
        "            augmented = self.apply_time_warping(augmented)\n",
        "\n",
        "        return augmented\n",
        "\n",
        "augmentation = OnTheFlyAugmentation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f62471f6"
      },
      "source": [
        "### Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_1hfiBVAMel",
        "outputId": "e1d26dc4-2689-4fd3-b202-6c5abf8c32c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating pd_vs_hc dataset (movement_only)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 355/355 [03:01<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 355 patients: {'HC': np.int64(79), 'PD': np.int64(276)}\n",
            "Creating SEGMENT dataset: pd_vs_hc (movement_only)\n",
            "[segment] Built 3905 samples (869 neg / 3036 pos); movement shape=(3905, 950, 12), quest shape=(3905, 30)\n",
            "Creating pd_vs_hc dataset (questionnaire_only)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 355/355 [00:00<00:00, 401.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 355 patients: {'HC': np.int64(79), 'PD': np.int64(276)}\n",
            "Creating SEGMENT dataset: pd_vs_hc (questionnaire_only)\n",
            "[segment] Built 3905 samples (869 neg / 3036 pos); movement shape=(3905, 950, 12), quest shape=(3905, 30)\n",
            "Creating pd_vs_hc dataset (combined)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 355/355 [00:00<00:00, 399.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 355 patients: {'HC': np.int64(79), 'PD': np.int64(276)}\n",
            "Creating SEGMENT dataset: pd_vs_hc (combined)\n",
            "[segment] Built 3905 samples (869 neg / 3036 pos); movement shape=(3905, 950, 12), quest shape=(3905, 30)\n",
            "Creating pd_vs_dd dataset (movement_only)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:58<00:00,  6.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 390 patients: {'DD': np.int64(114), 'PD': np.int64(276)}\n",
            "Creating SEGMENT dataset: pd_vs_dd (movement_only)\n",
            "[segment] Built 4290 samples (1254 neg / 3036 pos); movement shape=(4290, 950, 12), quest shape=(4290, 30)\n",
            "Creating pd_vs_dd dataset (questionnaire_only)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:01<00:00, 379.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 390 patients: {'DD': np.int64(114), 'PD': np.int64(276)}\n",
            "Creating SEGMENT dataset: pd_vs_dd (questionnaire_only)\n",
            "[segment] Built 4290 samples (1254 neg / 3036 pos); movement shape=(4290, 950, 12), quest shape=(4290, 30)\n",
            "Creating pd_vs_dd dataset (combined)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [00:00<00:00, 404.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 390 patients: {'DD': np.int64(114), 'PD': np.int64(276)}\n",
            "Creating SEGMENT dataset: pd_vs_dd (combined)\n",
            "[segment] Built 4290 samples (1254 neg / 3036 pos); movement shape=(4290, 950, 12), quest shape=(4290, 30)\n",
            "SUBJECT datasets: ['pd_vs_hc_movement_only', 'pd_vs_hc_questionnaire_only', 'pd_vs_hc_combined', 'pd_vs_dd_movement_only', 'pd_vs_dd_questionnaire_only', 'pd_vs_dd_combined']\n",
            "SEGMENT datasets: ['pd_vs_hc_movement_only', 'pd_vs_hc_questionnaire_only', 'pd_vs_hc_combined', 'pd_vs_dd_movement_only', 'pd_vs_dd_questionnaire_only', 'pd_vs_dd_combined']\n"
          ]
        }
      ],
      "source": [
        "def _to_quest_vector(quest_features: dict, size: int = 30) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert a dict of questionnaire features -> fixed-length vector.\n",
        "    Pads with zeros if fewer than `size` entries. Truncates otherwise.\n",
        "    \"\"\"\n",
        "    v = np.zeros(size, dtype=np.float32)\n",
        "    if not quest_features:\n",
        "        return v\n",
        "    items = list(quest_features.items())[:size]\n",
        "    for i, (_, val) in enumerate(items):\n",
        "        try:\n",
        "            v[i] = float(val)\n",
        "        except Exception:\n",
        "            v[i] = 0.0\n",
        "    return v\n",
        "\n",
        "class CleanDatasetCreator:\n",
        "    def __init__(self, data_pipeline):\n",
        "        self.data_pipeline = data_pipeline\n",
        "\n",
        "    def create_base_dataset(self, task_type='pd_vs_hc', modality='combined'):\n",
        "        print(f\"Creating {task_type} dataset ({modality})\")\n",
        "\n",
        "        if task_type == 'pd_vs_hc':\n",
        "            valid_conditions = [\"Parkinson's\", \"Healthy\"]\n",
        "            label_map = {\"Healthy\": 0, \"Parkinson's\": 1}\n",
        "        elif task_type == 'pd_vs_dd':\n",
        "            valid_conditions = [\"Parkinson's\", \"Other Movement Disorders\",\n",
        "                              \"Essential Tremor\", \"Atypical Parkinsonism\", \"Multiple Sclerosis\"]\n",
        "            label_map = {\"Parkinson's\": 1}\n",
        "            for cond in valid_conditions[1:]:\n",
        "                label_map[cond] = 0\n",
        "        else:\n",
        "            raise ValueError(\"Only classification tasks supported!\")\n",
        "\n",
        "        filtered_patients = self.data_pipeline.patient_metadata[\n",
        "            self.data_pipeline.patient_metadata['condition'].isin(valid_conditions)\n",
        "        ]\n",
        "\n",
        "        X_movement = []\n",
        "        X_questionnaire = []\n",
        "        y_labels = []\n",
        "        patient_ids = []\n",
        "        successful_loads = 0\n",
        "\n",
        "        for idx, row in tqdm(filtered_patients.iterrows(), total=len(filtered_patients)):\n",
        "          patient_id = int(row['id'])\n",
        "          pid_str    = f\"{patient_id:03d}\"\n",
        "          condition  = row['condition']\n",
        "\n",
        "          movement_data  = self.data_pipeline.load_bin_file_raw(patient_id)\n",
        "          quest_features = self.data_pipeline.questionnaire_data.get(pid_str, {})\n",
        "\n",
        "          has_mov   = movement_data is not None\n",
        "          has_quest = len(quest_features) >= 10\n",
        "\n",
        "          if modality == 'movement_only':\n",
        "              if has_mov:\n",
        "                  X_movement.append(movement_data.astype(np.float32))\n",
        "                  X_questionnaire.append(np.zeros(30, dtype=np.float32))\n",
        "                  y_labels.append(int(label_map[condition]))\n",
        "                  patient_ids.append(patient_id)\n",
        "                  successful_loads += 1\n",
        "\n",
        "          elif modality == 'questionnaire_only':\n",
        "              if has_quest:\n",
        "                  quest_vector = _to_quest_vector(quest_features, size=30)\n",
        "                  X_movement.append(np.zeros((950, 132), dtype=np.float32))\n",
        "                  X_questionnaire.append(quest_vector)\n",
        "                  y_labels.append(int(label_map[condition]))\n",
        "                  patient_ids.append(patient_id)\n",
        "                  successful_loads += 1\n",
        "\n",
        "          elif modality == 'combined':\n",
        "              if has_mov and has_quest:\n",
        "                  quest_vector = _to_quest_vector(quest_features, size=30)\n",
        "                  X_movement.append(movement_data.astype(np.float32))\n",
        "                  X_questionnaire.append(quest_vector)\n",
        "                  y_labels.append(int(label_map[condition]))\n",
        "                  patient_ids.append(patient_id)\n",
        "                  successful_loads += 1\n",
        "\n",
        "          else:\n",
        "              raise ValueError(\"Unsupported modality\")\n",
        "\n",
        "\n",
        "        X_movement = np.array(X_movement)\n",
        "        X_questionnaire = np.array(X_questionnaire)\n",
        "        y_labels = np.array(y_labels)\n",
        "\n",
        "        unique, counts = np.unique(y_labels, return_counts=True)\n",
        "        if task_type == 'pd_vs_hc':\n",
        "            class_names = ['HC', 'PD']\n",
        "        else:\n",
        "            class_names = ['DD', 'PD']\n",
        "\n",
        "        class_dist = dict(zip(class_names, counts))\n",
        "        print(f\"Loaded {successful_loads} patients: {class_dist}\")\n",
        "\n",
        "        return {\n",
        "            'X_movement': X_movement,\n",
        "            'X_questionnaire': X_questionnaire,\n",
        "            'y': y_labels,\n",
        "            'patient_ids': patient_ids,\n",
        "            'task_type': task_type,\n",
        "            'modality': modality,\n",
        "            'successful_loads': successful_loads\n",
        "        }\n",
        "# helper to slice 132->per-task 12ch\n",
        "def _slice_task_12ch(x132: np.ndarray, task_idx: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    x132: [T,132] ordered as 11 tasks × (Left/Right × Acc/Gyro × X/Y/Z) -> 11 * 12 = 132\n",
        "    task_idx: 0..10\n",
        "    returns [T,12]\n",
        "    \"\"\"\n",
        "    base = task_idx * 12\n",
        "    return x132[:, base:base+12].astype(np.float32)\n",
        "\n",
        "# segment-level dataset builder\n",
        "def create_segment_dataset(data_pipeline, task_type='pd_vs_hc', modality='movement_only'):\n",
        "    print(f\"Creating SEGMENT dataset: {task_type} ({modality})\")\n",
        "\n",
        "    if task_type == 'pd_vs_hc':\n",
        "        valid_conditions = [\"Parkinson's\", \"Healthy\"]\n",
        "        label_map = {\"Healthy\": 0, \"Parkinson's\": 1}\n",
        "    elif task_type == 'pd_vs_dd':\n",
        "        valid_conditions = [\"Parkinson's\", \"Other Movement Disorders\",\n",
        "                            \"Essential Tremor\", \"Atypical Parkinsonism\", \"Multiple Sclerosis\"]\n",
        "        label_map = {\"Parkinson's\": 1}\n",
        "        for cond in valid_conditions[1:]:\n",
        "            label_map[cond] = 0\n",
        "    else:\n",
        "        raise ValueError(\"Only classification tasks supported!\")\n",
        "\n",
        "    filtered = data_pipeline.patient_metadata[\n",
        "        data_pipeline.patient_metadata['condition'].isin(valid_conditions)\n",
        "    ]\n",
        "\n",
        "    X_movement, X_questionnaire, y, pids = [], [], [], []\n",
        "    TASKS_N = 11  # physio dataset has 11 tasks → 11×12ch = 132\n",
        "\n",
        "    for _, row in filtered.iterrows():\n",
        "        sid = int(row['id']); pid_str = f\"{sid:03d}\"\n",
        "        cond = row['condition']\n",
        "\n",
        "        mov132 = data_pipeline.load_bin_file_raw(sid)        # [950,132] or None\n",
        "        quest  = data_pipeline.questionnaire_data.get(pid_str, {})\n",
        "        has_mov   = mov132 is not None\n",
        "        has_quest = len(quest) >= 10\n",
        "\n",
        "        # make a fixed 30-d questionnaire vector (or zeros)\n",
        "        quest_vec = np.zeros(30, dtype=np.float32)\n",
        "        if has_quest:\n",
        "            q = _to_quest_vector(quest, size=30)\n",
        "            quest_vec = q.astype(np.float32)\n",
        "\n",
        "        # explode to segments\n",
        "        for t in range(TASKS_N):\n",
        "            # decide inclusion by modality\n",
        "            if modality == 'movement_only' and has_mov:\n",
        "                x12 = _slice_task_12ch(mov132, t)  # [950,12]\n",
        "                X_movement.append(x12)\n",
        "                X_questionnaire.append(np.zeros(30, dtype=np.float32))\n",
        "                y.append(int(label_map[cond]))\n",
        "                pids.append(sid)\n",
        "\n",
        "            elif modality == 'questionnaire_only' and has_quest:\n",
        "                # no movement, but keep 12ch placeholder for consistency\n",
        "                X_movement.append(np.zeros((950, 12), dtype=np.float32))\n",
        "                X_questionnaire.append(quest_vec)\n",
        "                y.append(int(label_map[cond]))\n",
        "                pids.append(sid)\n",
        "\n",
        "            elif modality == 'combined' and has_mov and has_quest:\n",
        "                x12 = _slice_task_12ch(mov132, t)\n",
        "                X_movement.append(x12)\n",
        "                X_questionnaire.append(quest_vec)\n",
        "                y.append(int(label_map[cond]))\n",
        "                pids.append(sid)\n",
        "\n",
        "    X_movement      = np.asarray(X_movement, dtype=np.float32)       # [Nseg, 950, 12]\n",
        "    X_questionnaire = np.asarray(X_questionnaire, dtype=np.float32)  # [Nseg, 30]\n",
        "    y               = np.asarray(y, dtype=np.int64)\n",
        "\n",
        "    print(f\"[segment] Built {len(y)} samples \"\n",
        "          f\"({np.sum(y==0)} neg / {np.sum(y==1)} pos); \"\n",
        "          f\"movement shape={X_movement.shape}, quest shape={X_questionnaire.shape}\")\n",
        "\n",
        "    return {\n",
        "        'X_movement': X_movement,\n",
        "        'X_questionnaire': X_questionnaire,\n",
        "        'y': y,\n",
        "        'patient_ids': pids,\n",
        "        'task_type': task_type,\n",
        "        'modality': modality,\n",
        "        'split_unit': 'segment'\n",
        "    }\n",
        "dataset_creator = CleanDatasetCreator(data_pipeline)\n",
        "# build both SUBJECT and SEGMENT datasets\n",
        "datasets_subject = {}\n",
        "datasets_segment = {}\n",
        "\n",
        "for task in ['pd_vs_hc', 'pd_vs_dd']:\n",
        "    for modality in ['movement_only', 'questionnaire_only', 'combined']:\n",
        "        key = f'{task}_{modality}'\n",
        "\n",
        "        # SUBJECT version\n",
        "        datasets_subject[key] = dataset_creator.create_base_dataset(task, modality)\n",
        "\n",
        "        # SEGMENT version (12ch per segment)\n",
        "        datasets_segment[key] = create_segment_dataset(data_pipeline, task, modality)\n",
        "\n",
        "# Convenience mapping so we can pick by SPLIT_UNIT later\n",
        "DATASET_POOLS = {\n",
        "    \"subject\": datasets_subject,\n",
        "    \"segment\": datasets_segment,\n",
        "}\n",
        "print(f\"SUBJECT datasets: {list(datasets_subject.keys())}\")\n",
        "print(f\"SEGMENT datasets: {list(datasets_segment.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "397431a6"
      },
      "source": [
        "### Model Definitions (Universal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rgUZr3V_APFh"
      },
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction_ratio, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channels // reduction_ratio, channels, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, _ = x.size()\n",
        "        y = self.avg_pool(x).view(batch_size, channels)\n",
        "        y = self.mlp(y)\n",
        "        y = self.sigmoid(y).view(batch_size, channels, 1)\n",
        "        return y\n",
        "\n",
        "class CA_LSTM_FCN(nn.Module):\n",
        "    \"\"\"\n",
        "    FCN(8/5/3)+ChannelAttention+GAP  ||  LSTM(last state)  -> concat -> head\n",
        "    - num_classes=2 -> CrossEntropy (baseline)\n",
        "    Handles all modalities gracefully: movement_only / questionnaire_only / combined\n",
        "    \"\"\"\n",
        "    def __init__(self, input_channels=12, sequence_length=950, num_classes=1,\n",
        "                 questionnaire_features=30, lstm_hidden_size=128,\n",
        "                 fcn_filters=(128,256,128), dropout=0.2, modality='movement_only'):\n",
        "        super().__init__()\n",
        "        self.modality = modality\n",
        "        self.use_move  = modality in ('movement_only','combined')\n",
        "        self.use_quest = modality in ('questionnaire_only','combined')\n",
        "\n",
        "        # --- Movement branch (optional) ---\n",
        "        movement_feat_dim = 0\n",
        "        if self.use_move:\n",
        "            C = input_channels\n",
        "            self.fcn = nn.Sequential(\n",
        "                nn.Conv1d(C, fcn_filters[0], kernel_size=8, padding=4),\n",
        "                nn.BatchNorm1d(fcn_filters[0]), nn.ReLU(),\n",
        "                nn.Conv1d(fcn_filters[0], fcn_filters[1], kernel_size=5, padding=2),\n",
        "                nn.BatchNorm1d(fcn_filters[1]), nn.ReLU(),\n",
        "                nn.Conv1d(fcn_filters[1], fcn_filters[2], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm1d(fcn_filters[2]), nn.ReLU(),\n",
        "            )\n",
        "            self.cam = ChannelAttention(fcn_filters[-1])\n",
        "            self.gap = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size=C,\n",
        "                hidden_size=lstm_hidden_size,\n",
        "                num_layers=1,\n",
        "                batch_first=True,\n",
        "                dropout=0.0,\n",
        "                bidirectional=False\n",
        "            )\n",
        "            self.dp_lstm = nn.Dropout(dropout)\n",
        "            movement_feat_dim = fcn_filters[-1] + lstm_hidden_size\n",
        "        else:\n",
        "            # placeholders so attributes exist even if unused\n",
        "            self.fcn = None\n",
        "            self.cam = None\n",
        "            self.gap = None\n",
        "            self.lstm = None\n",
        "            self.dp_lstm = None\n",
        "\n",
        "        # --- Questionnaire branch (optional) ---\n",
        "        self.qhead = None\n",
        "        q_dim = 0\n",
        "        if self.use_quest:\n",
        "            self.qhead = nn.Sequential(\n",
        "                nn.Linear(questionnaire_features, 64), nn.ReLU(), nn.Dropout(dropout),\n",
        "                nn.Linear(64, 128), nn.ReLU(), nn.Dropout(dropout)\n",
        "            )\n",
        "            q_dim = 128\n",
        "\n",
        "        # --- Fusion head ---\n",
        "        fused_dim = movement_feat_dim + q_dim\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(fused_dim, 128), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # --- Weight initialization ---\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                if m.bias is not None: nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, movement_data, clinical_data):\n",
        "        feats = []\n",
        "\n",
        "        if self.use_move and movement_data is not None and movement_data.numel() > 0:\n",
        "            x = movement_data\n",
        "            f = self.fcn(x.transpose(1, 2))\n",
        "            f = f * self.cam(f)\n",
        "            f = self.gap(f).squeeze(-1)\n",
        "            h, _ = self.lstm(x)\n",
        "            m = self.dp_lstm(h[:, -1, :])\n",
        "            feats.extend([f, m])\n",
        "\n",
        "        if self.use_quest and clinical_data is not None and clinical_data.numel() > 0:\n",
        "            q = self.qhead(clinical_data)\n",
        "            feats.append(q)\n",
        "\n",
        "        if not feats:\n",
        "            raise RuntimeError(\"CA_LSTM_FCN received no valid inputs (check modality configuration).\")\n",
        "\n",
        "        z = torch.cat(feats, dim=1)\n",
        "        return self.head(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wQV83hSPBJ0S"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesTransformerConfig(PretrainedConfig):\n",
        "    model_type = \"time_series_transformer\"\n",
        "\n",
        "    def __init__(self, sequence_length=950, input_channels=132, num_classes=2,\n",
        "                 questionnaire_features=30, d_model=256, nhead=8, num_layers=4,\n",
        "                 dropout=0.1, modality='combined', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_channels = input_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.questionnaire_features = questionnaire_features\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.modality = modality\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=1024):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))  # [1, max_len, d_model]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, d]\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "\n",
        "class TimeSeriesTransformer(PreTrainedModel):\n",
        "    config_class = TimeSeriesTransformerConfig\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.config = config\n",
        "\n",
        "        self.use_movement = config.modality in ['movement_only', 'combined']\n",
        "        self.use_questionnaire = config.modality in ['questionnaire_only', 'combined']\n",
        "\n",
        "        # Projections\n",
        "        if self.use_movement:\n",
        "            self.movement_projection = nn.Linear(config.input_channels, config.d_model)\n",
        "        if self.use_questionnaire:\n",
        "            self.questionnaire_projection = nn.Linear(config.questionnaire_features, config.d_model)\n",
        "            if self.use_movement:\n",
        "                # Early fusion: per-timestep concat(movement, questionnaire) -> project back to d_model\n",
        "                self.early_fusion = nn.Sequential(\n",
        "                    nn.Linear(config.d_model * 2, config.d_model),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(config.dropout)\n",
        "                )\n",
        "\n",
        "        # +1 for CLS token (max sequence length we need to encode)\n",
        "        max_seq_len = config.sequence_length + 1\n",
        "        self.pos_encoding = PositionalEncoding(config.d_model, max_seq_len)\n",
        "        self.input_layer_norm = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        # CLS token\n",
        "        self.cls = nn.Parameter(torch.randn(1, 1, config.d_model))\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=config.d_model,\n",
        "            nhead=config.nhead,\n",
        "            dim_feedforward=config.d_model * 4,\n",
        "            dropout=config.dropout,\n",
        "            activation='relu',\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=config.num_layers,\n",
        "            norm=nn.LayerNorm(config.d_model)\n",
        "        )\n",
        "\n",
        "        # Classifier on CLS\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(config.d_model),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.d_model, config.d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config.dropout),\n",
        "            nn.Linear(config.d_model // 2, config.num_classes)\n",
        "        )\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, movement_data, clinical_data=None, key_padding_mask=None):\n",
        "        \"\"\"\n",
        "        movement_data: [B, T, C]\n",
        "        clinical_data: [B, F] or None\n",
        "        key_padding_mask (optional): [B, T] with True marking PAD positions (if you use variable T)\n",
        "        \"\"\"\n",
        "        if not (self.use_movement or self.use_questionnaire):\n",
        "            raise ValueError(\"Model modality must be one of ['movement_only','questionnaire_only','combined'].\")\n",
        "\n",
        "        sequences = []\n",
        "\n",
        "        if self.use_movement and self.use_questionnaire:\n",
        "            # Project movement to d_model\n",
        "            mov = self.movement_projection(movement_data)                 # [B, T, d]\n",
        "            # Project questionnaire to d_model and tile across time\n",
        "            que = self.questionnaire_projection(clinical_data)            # [B, d]\n",
        "            que_tiled = que.unsqueeze(1).expand(-1, mov.size(1), -1)      # [B, T, d]\n",
        "            fused = torch.cat([mov, que_tiled], dim=-1)                   # [B, T, 2d]\n",
        "            x = self.early_fusion(fused)                                  # [B, T, d]\n",
        "            sequences.append(x)\n",
        "\n",
        "        elif self.use_movement:\n",
        "            x = self.movement_projection(movement_data)                   # [B, T, d]\n",
        "            sequences.append(x)\n",
        "\n",
        "        elif self.use_questionnaire:\n",
        "            que = self.questionnaire_projection(clinical_data)            # [B, d]\n",
        "            x = que.unsqueeze(1)                                          # [B, 1, d]\n",
        "            sequences.append(x)\n",
        "\n",
        "        x = torch.cat(sequences, dim=1) if len(sequences) > 1 else sequences[0]  # [B, T_or_1, d]\n",
        "\n",
        "        # Prepend CLS\n",
        "        B = x.size(0)\n",
        "        cls_tok = self.cls.expand(B, 1, -1)                               # [B, 1, d]\n",
        "        x = torch.cat([cls_tok, x], dim=1)                                # [B, 1+T, d]\n",
        "\n",
        "        # Optional key padding mask: prepend False for CLS\n",
        "        kpm = None\n",
        "        if key_padding_mask is not None:\n",
        "            if key_padding_mask.dim() != 2 or key_padding_mask.size(0) != B:\n",
        "                raise ValueError(\"key_padding_mask must be [B, T]\")\n",
        "            kpm = torch.cat([torch.zeros(B, 1, dtype=torch.bool, device=key_padding_mask.device),\n",
        "                             key_padding_mask], dim=1)                     # [B, 1+T]\n",
        "\n",
        "        # Encode (LN -> PE -> Transformer)\n",
        "        x = self.input_layer_norm(x)\n",
        "        x = self.pos_encoding(x)  # add sinusoidal PE\n",
        "        h = self.transformer_encoder(x, src_key_padding_mask=kpm)\n",
        "\n",
        "\n",
        "        # CLS pooling\n",
        "        z = h[:, 0, :]                                                    # [B, d]\n",
        "        logits = self.classifier(z)                                       # [B, num_classes]\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a80014f"
      },
      "source": [
        "### Model Hyperparameter Search Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26d510f4",
        "outputId": "0aef2ffd-25cd-49dd-9afd-7d6edf1cbcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finalized hyperparameters for tuning:\n",
            "- CA-LSTM-FCN:\n",
            "  - lstm_hidden_size: [64, 128]\n",
            "  - fcn_filters: [[64, 128, 64], [128, 256, 128]]\n",
            "  - dropout: [0.1, 0.2]\n",
            "- Transformer:\n",
            "  - d_model: [128, 256]\n",
            "  - nhead: [4, 8]\n",
            "  - num_layers: [2, 3]\n",
            "  - dropout: [0.1, 0.2]\n"
          ]
        }
      ],
      "source": [
        "# hyperparameter search space\n",
        "model_hyperparameters = {\n",
        "    'CA-LSTM-FCN': {\n",
        "        'lstm_hidden_size': [64, 128],\n",
        "        'fcn_filters': [[64, 128, 64], [128, 256, 128]],\n",
        "        'dropout': [0.1, 0.2]\n",
        "    },\n",
        "    'Transformer': {\n",
        "        'd_model': [128, 256],\n",
        "        'nhead': [4, 8],\n",
        "        'num_layers': [2, 3],\n",
        "        'dropout': [0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Finalized hyperparameters for tuning:\")\n",
        "for model_name, params in model_hyperparameters.items():\n",
        "    print(f\"- {model_name}:\")\n",
        "    for hp, values in params.items():\n",
        "        print(f\"  - {hp}: {values}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5588cd33"
      },
      "source": [
        "### Dataset and Trainer Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6f8c750d"
      },
      "outputs": [],
      "source": [
        "# ---- Dataset ----\n",
        "class TrainingDataset(Dataset):\n",
        "    def __init__(self, movement_data, clinical_data, labels, indices,\n",
        "                 movement_scaler=None, clinical_scaler=None,\n",
        "                 augmentation=None, is_training=False, modality='combined'):\n",
        "\n",
        "        self.movement_data = movement_data[indices]\n",
        "        self.clinical_data = clinical_data[indices]\n",
        "        self.labels = labels[indices]\n",
        "        self.movement_scaler = movement_scaler\n",
        "        self.clinical_scaler = clinical_scaler\n",
        "        self.augmentation = augmentation\n",
        "        self.is_training = is_training\n",
        "        self.modality = modality\n",
        "        self.paper_parity = False  # default; set True for parity runs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        movement = self.movement_data[idx].copy()\n",
        "        clinical = self.clinical_data[idx].copy()\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        # --- 1. Scale movement ---\n",
        "        if self.movement_scaler is not None and self.modality in ['movement_only', 'combined']:\n",
        "            T, C = movement.shape[-2], movement.shape[-1]\n",
        "            movement = self.movement_scaler.transform(movement.reshape(-1, C)).reshape(T, C)\n",
        "\n",
        "        # --- 2. Paper-parity additive Gaussian noise (only in training) ---\n",
        "        if self.is_training and self.paper_parity and self.modality in ['movement_only','combined']:\n",
        "            movement += np.random.normal(0.0, 0.01, size=movement.shape).astype(np.float32)\n",
        "\n",
        "        # --- 3. Scale clinical features ---\n",
        "        if self.clinical_scaler is not None and self.modality in ['questionnaire_only', 'combined']:\n",
        "            clinical = self.clinical_scaler.transform(clinical.reshape(1, -1)).ravel()\n",
        "\n",
        "        # --- 4. Baseline augmentation (disabled if paper_parity=True) ---\n",
        "        if self.is_training and not self.paper_parity and self.augmentation is not None \\\n",
        "          and self.modality in ['movement_only','combined']:\n",
        "\n",
        "            model_name = getattr(self, 'current_model_name', None)\n",
        "            if label == 0:  # augment controls only\n",
        "                if model_name == 'CA-LSTM-FCN':\n",
        "                    # stronger augmentations\n",
        "                    if np.random.rand() < 0.6:\n",
        "                        movement = self.augmentation.apply_axis_rotation(movement, max_angle=12)\n",
        "                    if np.random.rand() < 0.4:\n",
        "                        movement = self.augmentation.apply_time_warping(movement, sigma=0.20, knot=4)\n",
        "                    if np.random.rand() < 0.2:\n",
        "                        movement += np.random.normal(0, 0.01, movement.shape)\n",
        "                else:\n",
        "                    # default weaker augmentations\n",
        "                    if np.random.rand() < 0.6:\n",
        "                        movement = self.augmentation.apply_axis_rotation(movement, max_angle=5)\n",
        "                    if np.random.rand() < 0.4:\n",
        "                        movement = self.augmentation.apply_time_warping(movement, sigma=0.10, knot=4)\n",
        "\n",
        "        return (\n",
        "            torch.tensor(movement, dtype=torch.float32),\n",
        "            torch.tensor(clinical, dtype=torch.float32),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "# ---- Trainer ----\n",
        "class Trainer:\n",
        "    def __init__(self, device='cuda'):\n",
        "        self.device = device\n",
        "        self.augmentation = OnTheFlyAugmentation()\n",
        "        self.paper_parity = False\n",
        "\n",
        "    def train_single_fold(self, model, train_dataset, val_dataset, max_epochs, fold_num):\n",
        "        model = model.to(self.device)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "        val_loader   = DataLoader(val_dataset,   batch_size=64, shuffle=False)\n",
        "\n",
        "        # === 1. Criterion selection ===\n",
        "        if isinstance(model, CA_LSTM_FCN) and model.head[-1].out_features == 1:\n",
        "            criterion = nn.BCEWithLogitsLoss()\n",
        "        else:\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "        # === 2. Optimizer & scheduler ===\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "        if self.paper_parity:\n",
        "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=8)\n",
        "        else:\n",
        "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "\n",
        "        # === Best tracking / early stopping ===\n",
        "        # Monitor = F1 in parity mode (paper), else BA (previous baseline).\n",
        "        best_monitor = -1.0\n",
        "        patience = 35\n",
        "        patience_counter = 0\n",
        "\n",
        "        best_epoch = -1\n",
        "        best_at_monitor = {  # metrics at the epoch where the monitor is best\n",
        "            'acc': -1.0, 'ba': -1.0, 'prec': -1.0, 'rec': -1.0, 'f1': -1.0\n",
        "        }\n",
        "        # true maxima across epochs\n",
        "        best_ba_any_epoch = -1.0\n",
        "        best_f1_any_epoch = -1.0\n",
        "\n",
        "        # keep last-epoch metrics for reference\n",
        "        acc = ba = prec = rec = f1 = 0.0\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            # ---- Train ----\n",
        "            model.train()\n",
        "            train_loss_sum = 0.0\n",
        "            train_batches = 0\n",
        "            for movement_data, clinical_data, labels in train_loader:\n",
        "                movement_data = movement_data.to(self.device)\n",
        "                clinical_data = clinical_data.to(self.device)\n",
        "                labels        = labels.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(movement_data, clinical_data)\n",
        "\n",
        "                if isinstance(criterion, nn.BCEWithLogitsLoss):\n",
        "                    labels_float = labels.float().unsqueeze(1)\n",
        "                    loss = criterion(outputs, labels_float)\n",
        "                else:\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss_sum += float(loss.detach().cpu().item())\n",
        "                train_batches += 1\n",
        "\n",
        "            # ---- Validate ----\n",
        "            model.eval()\n",
        "            val_predictions, val_targets = [], []\n",
        "            val_loss_sum = 0.0\n",
        "            val_batches = 0\n",
        "            with torch.no_grad():\n",
        "                for movement_data, clinical_data, labels in val_loader:\n",
        "                    movement_data = movement_data.to(self.device)\n",
        "                    clinical_data = clinical_data.to(self.device)\n",
        "                    labels        = labels.to(self.device)\n",
        "\n",
        "                    outputs = model(movement_data, clinical_data)\n",
        "                    if isinstance(criterion, nn.BCEWithLogitsLoss):\n",
        "                        preds = (torch.sigmoid(outputs) > 0.5).long().cpu().numpy().flatten()\n",
        "                        vloss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "                    else:\n",
        "                        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "                        vloss = criterion(outputs, labels)\n",
        "\n",
        "                    val_predictions.extend(preds)\n",
        "                    val_targets.extend(labels.cpu().numpy())\n",
        "                    val_loss_sum += float(vloss.detach().cpu().item())\n",
        "                    val_batches += 1\n",
        "            # ---- Metrics ----\n",
        "            from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score\n",
        "            acc  = accuracy_score(val_targets, val_predictions)\n",
        "            ba   = balanced_accuracy_score(val_targets, val_predictions)\n",
        "            prec = precision_score(val_targets, val_predictions, zero_division=0)\n",
        "            rec  = recall_score(val_targets, val_predictions, zero_division=0)\n",
        "            f1   = f1_score(val_targets, val_predictions, zero_division=0)\n",
        "\n",
        "            # update \"true\" bests (independent of monitor)\n",
        "            if ba > best_ba_any_epoch:\n",
        "                best_ba_any_epoch = ba\n",
        "            if f1 > best_f1_any_epoch:\n",
        "                best_f1_any_epoch = f1\n",
        "\n",
        "            # choose monitor (for early stopping + plateau scheduler)\n",
        "            monitor = f1 if self.paper_parity else ba\n",
        "            if self.paper_parity:\n",
        "                scheduler.step(monitor)   # ReduceLROnPlateau needs a metric\n",
        "            else:\n",
        "                scheduler.step()          # cosine annealing ignores metric\n",
        "\n",
        "            # keep metrics at the best monitor epoch\n",
        "            if monitor > best_monitor:\n",
        "                best_monitor = monitor\n",
        "                best_epoch = epoch + 1\n",
        "                patience_counter = 0\n",
        "                best_at_monitor.update({'acc': acc, 'ba': ba, 'prec': prec, 'rec': rec, 'f1': f1})\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if epoch % 20 == 0 or epoch < 3:\n",
        "                tl = train_loss_sum / max(1, train_batches)\n",
        "                vl = val_loss_sum   / max(1, val_batches)\n",
        "                print(f\"    Fold {fold_num}, Epoch {epoch+1:3d}: \"\n",
        "                      f\"TrainLoss={tl:.4f} | ValLoss={vl:.4f} | \"\n",
        "                      f\"Acc={acc:.3f} | BA={ba:.3f} | F1={f1:.3f} | Prec={prec:.3f} | Rec={rec:.3f}\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"    Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        return {\n",
        "            'best_epoch': best_epoch,\n",
        "            'best_acc': best_at_monitor['acc'],\n",
        "            'best_ba': best_at_monitor['ba'],\n",
        "            'best_prec': best_at_monitor['prec'],\n",
        "            'best_rec': best_at_monitor['rec'],\n",
        "            'best_f1': best_at_monitor['f1'],\n",
        "\n",
        "            'best_ba_any_epoch': best_ba_any_epoch,\n",
        "            'best_f1_any_epoch': best_f1_any_epoch,\n",
        "\n",
        "            # last-epoch metrics\n",
        "            'last_acc': acc, 'last_ba': ba, 'last_prec': prec, 'last_rec': rec, 'last_f1': f1\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def comprehensive_evaluation(self, model_class, model_params_space, dataset, max_epochs=60):\n",
        "        task_type = dataset['task_type']\n",
        "        modality  = dataset['modality']\n",
        "        model_name = model_class.__name__\n",
        "        print(f\"\\nEvaluating {model_name} on {task_type} ({modality})\")\n",
        "\n",
        "        X_mov_train_val   = dataset['X_movement']\n",
        "        X_quest_train_val = dataset['X_questionnaire']\n",
        "        y_train_val       = dataset['y']\n",
        "\n",
        "        patient_ids_train_val = dataset.get('patient_ids', None)\n",
        "\n",
        "        print(\"  Using full dataset for CV.\")\n",
        "\n",
        "        # --- Hyperparameter Tuning Loop ---\n",
        "        best_cv_score = -1.0\n",
        "        best_hyperparameters = None\n",
        "        best_fold_scores = None\n",
        "        best_model_state = None\n",
        "        best_movement_scaler_saved = None\n",
        "        best_clinical_scaler_saved = None\n",
        "\n",
        "        # grid\n",
        "        param_names  = list(model_params_space.keys())\n",
        "        param_values = list(model_params_space.values())\n",
        "        hp_grid = list(itertools.product(*param_values))\n",
        "        print(f\"  Starting Grid Search with {len(hp_grid)} combinations...\")\n",
        "\n",
        "        for hp_tuple in hp_grid:\n",
        "            current_params = dict(zip(param_names, hp_tuple))\n",
        "            print(f\"  Evaluating HPs: {current_params}\")\n",
        "\n",
        "            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            cv_splits = list(skf.split(X_mov_train_val, y_train_val))\n",
        "\n",
        "            fold_scores = []\n",
        "            fold_model_states = []\n",
        "            fold_movement_scalers = []\n",
        "            fold_clinical_scalers = []\n",
        "\n",
        "            for fold_idx, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "                # fit scalers on train only\n",
        "                movement_scaler = None\n",
        "                clinical_scaler = None\n",
        "                if modality in ['movement_only', 'combined']:\n",
        "                    movement_scaler = StandardScaler()\n",
        "                    Xtr_mov = X_mov_train_val[train_idx]\n",
        "                    movement_scaler.fit(Xtr_mov.reshape(-1, Xtr_mov.shape[-1]))\n",
        "                if modality in ['questionnaire_only', 'combined']:\n",
        "                    clinical_scaler = StandardScaler()\n",
        "                    clinical_scaler.fit(X_quest_train_val[train_idx])\n",
        "\n",
        "                # datasets\n",
        "                train_dataset = TrainingDataset(\n",
        "                    X_mov_train_val, X_quest_train_val, y_train_val,\n",
        "                    train_idx, movement_scaler, clinical_scaler,\n",
        "                    self.augmentation, is_training=True, modality=modality\n",
        "                )\n",
        "                val_dataset = TrainingDataset(\n",
        "                    X_mov_train_val, X_quest_train_val, y_train_val,\n",
        "                    val_idx, movement_scaler, clinical_scaler,\n",
        "                    None, is_training=False, modality=modality\n",
        "                )\n",
        "\n",
        "                # instantiate model\n",
        "                if model_class == TimeSeriesTransformer:\n",
        "                    config = TimeSeriesTransformerConfig(modality=modality, **current_params)\n",
        "                    model = TimeSeriesTransformer(config)\n",
        "                else:\n",
        "                    params_for_instantiation = {**current_params, 'modality': modality}\n",
        "                    model = model_class(**params_for_instantiation)\n",
        "\n",
        "                # train fold\n",
        "                fold_score = self.train_single_fold(\n",
        "                    model, train_dataset, val_dataset, max_epochs, fold_idx+1\n",
        "                )\n",
        "                fold_scores.append(fold_score)\n",
        "\n",
        "                fold_model_states.append(model.state_dict())\n",
        "                fold_movement_scalers.append(movement_scaler)\n",
        "                fold_clinical_scalers.append(clinical_scaler)\n",
        "\n",
        "                # cleanup\n",
        "                del model\n",
        "                if torch.cuda.is_available():\n",
        "                    torch.cuda.empty_cache()\n",
        "                else:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            # per-hp stats\n",
        "            mean_cv_score = float(np.mean([fs['best_ba'] for fs in fold_scores]))\n",
        "            std_cv_score  = float(np.std(fold_scores))\n",
        "            print(f\"  HPs {current_params}: Mean CV Result = {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n",
        "\n",
        "            # best tracking\n",
        "            if mean_cv_score > best_cv_score:\n",
        "                best_cv_score = mean_cv_score\n",
        "                best_hyperparameters = current_params\n",
        "                best_fold_scores = list(fold_scores)\n",
        "\n",
        "                best_fold_index_in_hp_run = int(np.argmax(fold_scores))\n",
        "                best_model_state = fold_model_states[best_fold_index_in_hp_run]\n",
        "                best_movement_scaler_saved = fold_movement_scalers[best_fold_index_in_hp_run]\n",
        "                best_clinical_scaler_saved = fold_clinical_scalers[best_fold_index_in_hp_run]\n",
        "\n",
        "        print(f\"\\n  Best HPs found: {best_hyperparameters}\")\n",
        "        print(f\"  Best Mean CV Score: {best_cv_score:.4f}\")\n",
        "        best_std = float(np.std(best_fold_scores)) if best_fold_scores else None\n",
        "        print(f\"  Std of Best HP CV: {best_std if best_std is not None else 'N/A'}\")\n",
        "\n",
        "        return {\n",
        "            'best_hyperparameters': best_hyperparameters,\n",
        "            'mean_cv_score': best_cv_score,\n",
        "            'std_cv_score': best_std,\n",
        "            'fold_scores': best_fold_scores,\n",
        "            'best_model_state': best_model_state,\n",
        "            'best_movement_scaler': best_movement_scaler_saved,\n",
        "            'best_clinical_scaler': best_clinical_scaler_saved,\n",
        "        }\n",
        "\n",
        "trainer = Trainer(device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be57033d"
      },
      "source": [
        "### Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TQFbVNNvwsG",
        "outputId": "adfb7d14-21a8-460d-a7f3-2e13c1ebc195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models: ['CA-LSTM-FCN', 'Transformer']\n",
            "SUBJECT datasets: ['pd_vs_hc_movement_only', 'pd_vs_hc_questionnaire_only', 'pd_vs_hc_combined', 'pd_vs_dd_movement_only', 'pd_vs_dd_questionnaire_only', 'pd_vs_dd_combined']\n",
            "SEGMENT datasets: ['pd_vs_hc_movement_only', 'pd_vs_hc_questionnaire_only', 'pd_vs_hc_combined', 'pd_vs_dd_movement_only', 'pd_vs_dd_questionnaire_only', 'pd_vs_dd_combined']\n"
          ]
        }
      ],
      "source": [
        "# Define models and their hyperparameter search spaces\n",
        "models_config = {\n",
        "    'CA-LSTM-FCN': {\n",
        "        'class': CA_LSTM_FCN,\n",
        "        'params_space': model_hyperparameters['CA-LSTM-FCN']\n",
        "    },\n",
        "    'Transformer': {\n",
        "        'class': TimeSeriesTransformer,\n",
        "        'params_space': model_hyperparameters['Transformer']\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Models: {list(models_config.keys())}\")\n",
        "print(f\"SUBJECT datasets: {list(datasets_subject.keys())}\")\n",
        "print(f\"SEGMENT datasets: {list(datasets_segment.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9abc7b25"
      },
      "source": [
        "### Framework 1 Hyperparameter Tuning Run (no need to run this cell)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "7fc5e22c",
        "outputId": "de7b8bd2-651f-43f2-c219-3c22566bcd1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models: ['CA-LSTM-FCN', 'Transformer', '1D-CNN', 'LSTM', 'MLP']\n",
            "Datasets: ['pd_vs_hc_movement_only', 'pd_vs_hc_questionnaire_only', 'pd_vs_hc_combined', 'pd_vs_dd_movement_only', 'pd_vs_dd_questionnaire_only', 'pd_vs_dd_combined']\n",
            "DATASET: PD_VS_HC_MOVEMENT_ONLY\n",
            "--- CA-LSTM-FCN ---\n",
            "\n",
            "Evaluating CA_LSTM_FCN on pd_vs_hc (movement_only)\n",
            "  Using full dataset for CV.\n",
            "  Starting Grid Search with 8 combinations...\n",
            "  Evaluating HPs: {'lstm_hidden_size': 64, 'fcn_filters': [64, 128, 64], 'dropout': 0.1}\n",
            "    Fold 1, Epoch   1: Bal Acc=0.5000\n",
            "    Fold 1, Epoch   2: Bal Acc=0.5000\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-820644279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Pass the hyperparameter space to comprehensive_evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         result = trainer.comprehensive_evaluation(\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params_space'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1752885255.py\u001b[0m in \u001b[0;36mcomprehensive_evaluation\u001b[0;34m(self, model_class, model_params_space, dataset, max_epochs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# train fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 fold_score = self.train_single_fold(\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 )\n",
            "\u001b[0;32m/tmp/ipython-input-1752885255.py\u001b[0m in \u001b[0;36mtrain_single_fold\u001b[0;34m(self, model, train_dataset, val_dataset, max_epochs, fold_num)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mval_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mmovement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclinical_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                     \u001b[0mmovement_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovement_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0mclinical_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclinical_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1752885255.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmovement_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mmovement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovement_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovement_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# clinical scaling (fit must be on train only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # ==== Hyperparameter tuning / evaluation ====\n",
        "\n",
        "# # Choose which split unit you want to tune on\n",
        "# SPLIT_UNIT = \"subject\"   # or \"segment\" (use subject as default, segment is an experimentary case for data leakage demonstration)\n",
        "\n",
        "# # Optionally restrict which datasets/models to run (leave as None to run all)\n",
        "# TARGET_DATASET_NAMES = None\n",
        "# TARGET_MODEL_NAMES   = None\n",
        "\n",
        "# # Pick the correct pool\n",
        "# if SPLIT_UNIT not in DATASET_POOLS:\n",
        "#     raise ValueError(\"SPLIT_UNIT must be 'subject' or 'segment'\")\n",
        "# dataset_pool = DATASET_POOLS[SPLIT_UNIT]\n",
        "\n",
        "# # Resolve datasets to process\n",
        "# datasets_to_process = list(dataset_pool.items())\n",
        "# if TARGET_DATASET_NAMES:\n",
        "#     datasets_to_process = [(name, data) for name, data in datasets_to_process\n",
        "#                            if name in set(TARGET_DATASET_NAMES)]\n",
        "#     if not datasets_to_process:\n",
        "#         print(f\"Warning: no datasets matched TARGET_DATASET_NAMES: {TARGET_DATASET_NAMES}\")\n",
        "\n",
        "# # Resolve models to process (keep order of TARGET_MODEL_NAMES if given)\n",
        "# models_to_process = list(models_config.items())\n",
        "# if TARGET_MODEL_NAMES:\n",
        "#     missing = [m for m in TARGET_MODEL_NAMES if m not in models_config]\n",
        "#     if missing:\n",
        "#         print(f\"Warning: unknown models in TARGET_MODEL_NAMES: {missing}\")\n",
        "#     models_to_process = [(m, models_config[m]) for m in TARGET_MODEL_NAMES if m in models_config]\n",
        "\n",
        "# print(\"Datasets to process:\", [n for n, _ in datasets_to_process])\n",
        "# print(\"Models to process:\",   [n for n, _ in models_to_process])\n",
        "\n",
        "# all_results = {}\n",
        "# for dataset_name, dataset in datasets_to_process:\n",
        "#     print(f\"\\nDATASET: {dataset_name.upper()}\")\n",
        "#     task_results = {}\n",
        "\n",
        "#     for model_name, model_config in models_to_process:\n",
        "#         print(f\"--- {model_name} ---\")\n",
        "#         result = trainer.comprehensive_evaluation(\n",
        "#             model_config['class'],\n",
        "#             model_config['params_space'],\n",
        "#             dataset,\n",
        "#             max_epochs=60\n",
        "#         )\n",
        "#         task_results[model_name] = result\n",
        "\n",
        "#     all_results[dataset_name] = task_results\n",
        "\n",
        "# # ---- Summarize & save ----\n",
        "# print(\"\\nCREATING RESULTS SUMMARY\")\n",
        "# rows = []\n",
        "# for dataset_name, task_results in all_results.items():\n",
        "#     for model_name, result in task_results.items():\n",
        "#         rows.append({\n",
        "#             'Dataset': dataset_name,\n",
        "#             'Model': model_name,\n",
        "#             'Best_Hyperparameters': result['best_hyperparameters'],\n",
        "#             'Mean_CV_Score': result['mean_cv_score'],\n",
        "#             'Std_CV_Score': result['std_cv_score'],\n",
        "#         })\n",
        "\n",
        "# results_df = pd.DataFrame(rows)\n",
        "# print(f\"Results summary: {len(results_df)} entries\")\n",
        "\n",
        "# out_csv = RESULTS_DIR / 'evaluation_results_with_hp_tuning.csv'\n",
        "# results_df.to_csv(out_csv, index=False)\n",
        "# print(f\"Results saved to: {out_csv}\")\n",
        "\n",
        "# print(\"\\nTOP RESULTS (Sorted by Mean CV Score):\")\n",
        "# if not results_df.empty:\n",
        "#     top_results = results_df.sort_values('Mean_CV_Score', ascending=False).head(10)\n",
        "#     print(top_results[['Dataset', 'Model', 'Best_Hyperparameters', 'Mean_CV_Score', 'Std_CV_Score']].to_string(index=False))\n",
        "# else:\n",
        "#     print(\"No results to display.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSZPc6RM42K3"
      },
      "source": [
        "### Framework 1 Evaluation with Best Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "2dd37d98",
        "outputId": "1debdbb7-2d8d-4496-c4f5-09c3469d7613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded HP results from: /content/drive/MyDrive/pads/results/evaluation_results_with_hp_tuning.csv\n",
            "Models to process (in order): ['Transformer', 'CA-LSTM-FCN']\n",
            "\n",
            "Starting evaluation with best hyperparameters...\n",
            "\n",
            "--- Evaluating on Dataset: PD_VS_HC_MOVEMENT_ONLY ---\n",
            "\n",
            "  Evaluating Model: Transformer\n",
            "  Loaded/Using Hyperparameters: {'d_model': 128, 'nhead': 4, 'num_layers': 3, 'dropout': 0.2}\n",
            "    Fold 1, Epoch   1: TrainLoss=0.6370 | ValLoss=0.5970 | Acc=0.775 | BA=0.500 | F1=0.873 | Prec=0.775 | Rec=1.000\n",
            "    Fold 1, Epoch   2: TrainLoss=0.5828 | ValLoss=0.5983 | Acc=0.775 | BA=0.500 | F1=0.873 | Prec=0.775 | Rec=1.000\n",
            "    Fold 1, Epoch   3: TrainLoss=0.5643 | ValLoss=0.5940 | Acc=0.775 | BA=0.500 | F1=0.873 | Prec=0.775 | Rec=1.000\n",
            "    Fold 1, Epoch  21: TrainLoss=0.3193 | ValLoss=0.6438 | Acc=0.789 | BA=0.642 | F1=0.870 | Prec=0.833 | Rec=0.909\n",
            "    Fold 1, Epoch  41: TrainLoss=0.2059 | ValLoss=0.6859 | Acc=0.817 | BA=0.793 | F1=0.876 | Prec=0.920 | Rec=0.836\n",
            "    Fold 1, Epoch  61: TrainLoss=0.2012 | ValLoss=0.7604 | Acc=0.817 | BA=0.727 | F1=0.883 | Prec=0.875 | Rec=0.891\n",
            "    Early stopping at epoch 67\n",
            "[Fold 1] Acc=0.8873  BA=0.8608  Prec=0.9434  Rec=0.9091  F1=0.9259  (best epoch 32)\n",
            "    Fold 2, Epoch   1: TrainLoss=0.6331 | ValLoss=0.6381 | Acc=0.775 | BA=0.500 | F1=0.873 | Prec=0.775 | Rec=1.000\n",
            "    Fold 2, Epoch   2: TrainLoss=0.5729 | ValLoss=0.6741 | Acc=0.775 | BA=0.500 | F1=0.873 | Prec=0.775 | Rec=1.000\n",
            "    Fold 2, Epoch   3: TrainLoss=0.5623 | ValLoss=0.6536 | Acc=0.775 | BA=0.500 | F1=0.873 | Prec=0.775 | Rec=1.000\n",
            "    Fold 2, Epoch  21: TrainLoss=0.2722 | ValLoss=0.8433 | Acc=0.690 | BA=0.578 | F1=0.796 | Prec=0.811 | Rec=0.782\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3522351518.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    276\u001b[0m                  \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             fold_metrics = trainer_single_run.train_single_fold(\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             )\n",
            "\u001b[0;32m/tmp/ipython-input-928042777.py\u001b[0m in \u001b[0;36mtrain_single_fold\u001b[0;34m(self, model, train_dataset, val_dataset, max_epochs, fold_num)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mmovement_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclinical_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mmovement_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovement_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                     \u001b[0mclinical_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclinical_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlabels\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# === Framework 1 Evaluation with Best Hyperparameters ===\n",
        "\n",
        "# --- Configuration ---\n",
        "# Specify the datasets and models you want to evaluate with best HPs\n",
        "# Set to None or empty list [] to evaluate all available datasets/models\n",
        "TARGET_DATASET_NAMES = [\"pd_vs_hc_movement_only\",\"pd_vs_hc_questionnaire_only\",\"pd_vs_hc_combined\",\"pd_vs_dd_movement_only\",\"pd_vs_dd_questionnaire_only\",\"pd_vs_dd_combined\"] # Example: ['pd_vs_hc_combined', 'pd_vs_dd_combined'] or None\n",
        "TARGET_MODEL_NAMES   = [\"Transformer\",\"CA-LSTM-FCN\"]      # Example: ['Transformer', 'CA-LSTM-FCN'] or None\n",
        "SPLIT_UNIT = \"subject\"  # or \"subject\" --> Segment gives us biased results due to data leakage, use it with CALSTMFCN for paper comparison\n",
        "PAPER_PARITY = False # flag to run with CALSTMFCN to compare with the Yu2024 electronics paper results for data leakage\n",
        "\n",
        "# --- Choose dataset pool based on SPLIT_UNIT ---\n",
        "if SPLIT_UNIT not in DATASET_POOLS:\n",
        "    raise ValueError(\"SPLIT_UNIT must be 'subject' or 'segment'\")\n",
        "dataset_pool = DATASET_POOLS[SPLIT_UNIT]\n",
        "\n",
        "if 'datasets_subject' not in globals() or 'datasets_segment' not in globals():\n",
        "    raise ValueError(\"Dataset pools not found. Please run the data preparation cells that build datasets_subject and datasets_segment.\")\n",
        "\n",
        "# --- Load Best Hyperparameters Results ---\n",
        "HP_CSV_PATH = RESULTS_DIR / 'evaluation_results_with_hp_tuning.csv'\n",
        "\n",
        "try:\n",
        "    hp_df_eval = pd.read_csv(HP_CSV_PATH)\n",
        "    print(f\"Loaded HP results from: {HP_CSV_PATH}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: HP results CSV not found at {HP_CSV_PATH}. Cannot load best hyperparameters.\")\n",
        "    hp_df_eval = pd.DataFrame()\n",
        "\n",
        "\n",
        "# --- Prepare Trainer ---\n",
        "trainer_single_run = Trainer(device=device)\n",
        "\n",
        "# --- Choose dataset pool based on SPLIT_UNIT ---\n",
        "if SPLIT_UNIT == \"subject\":\n",
        "    dataset_pool = datasets_subject\n",
        "elif SPLIT_UNIT == \"segment\":\n",
        "    dataset_pool = datasets_segment\n",
        "else:\n",
        "    raise ValueError(\"SPLIT_UNIT must be 'subject' or 'segment'\")\n",
        "\n",
        "# --- Determine which datasets and models to evaluate ---\n",
        "datasets_to_process = dataset_pool.items()\n",
        "if TARGET_DATASET_NAMES:\n",
        "    datasets_to_process = [(name, data) for name, data in dataset_pool.items()\n",
        "                           if name in TARGET_DATASET_NAMES]\n",
        "    if not datasets_to_process:\n",
        "        print(f\"Warning: No datasets found matching TARGET_DATASET_NAMES: {TARGET_DATASET_NAMES}\")\n",
        "\n",
        "# Build models_to_process in the exact order of TARGET_MODEL_NAMES\n",
        "if TARGET_MODEL_NAMES:\n",
        "    missing = [m for m in TARGET_MODEL_NAMES if m not in models_config]\n",
        "    if missing:\n",
        "        print(f\"Warning: These models are not in models_config and will be skipped: {missing}\")\n",
        "    models_to_process = [(name, models_config[name]) for name in TARGET_MODEL_NAMES if name in models_config]\n",
        "else:\n",
        "    models_to_process = list(models_config.items())\n",
        "\n",
        "print(\"Models to process (in order):\", [name for name, _ in models_to_process])\n",
        "\n",
        "print(\"\\nStarting evaluation with best hyperparameters...\")\n",
        "\n",
        "all_best_hp_results = []\n",
        "\n",
        "# Loop through selected datasets\n",
        "for dataset_name, dataset_to_evaluate in datasets_to_process:\n",
        "    print(f\"\\n--- Evaluating on Dataset: {dataset_name.upper()} ---\")\n",
        "\n",
        "    X_mov_train_val   = dataset_to_evaluate['X_movement']\n",
        "    X_quest_train_val = dataset_to_evaluate['X_questionnaire']\n",
        "    y_train_val       = dataset_to_evaluate['y']\n",
        "    modality          = dataset_to_evaluate['modality']\n",
        "    task_type         = dataset_to_evaluate['task_type']\n",
        "\n",
        "\n",
        "    # Loop through selected models\n",
        "    for model_name, model_config in models_to_process:\n",
        "        print(f\"\\n  Evaluating Model: {model_name}\")\n",
        "\n",
        "        # --- Load Best Hyperparameters for the Current Model and Dataset ---\n",
        "        best_hps = {}\n",
        "        if not hp_df_eval.empty:\n",
        "            # Find the best HP row for this specific dataset and model\n",
        "            expected_model_name_in_csv = f\"{model_name}-EarlyFusion\"\n",
        "            if expected_model_name_in_csv not in hp_df_eval['Model'].unique():\n",
        "                 expected_model_name_in_csv = model_name\n",
        "                 if expected_model_name_in_csv not in hp_df_eval['Model'].unique():\n",
        "                      print(f\"  Warning: Model name '{model_name}' or '{model_name}-EarlyFusion' not found in CSV. Using default HPs.\")\n",
        "                      filtered_hps = pd.DataFrame()\n",
        "                 else:\n",
        "                      filtered_hps = hp_df_eval[\n",
        "                         (hp_df_eval['Dataset'] == dataset_name) &\n",
        "                         (hp_df_eval['Model'] == expected_model_name_in_csv)\n",
        "                      ]\n",
        "            else:\n",
        "                 filtered_hps = hp_df_eval[\n",
        "                    (hp_df_eval['Dataset'] == dataset_name) &\n",
        "                    (hp_df_eval['Model'] == expected_model_name_in_csv)\n",
        "                 ]\n",
        "\n",
        "\n",
        "            if not filtered_hps.empty:\n",
        "                best_row = filtered_hps.sort_values('Mean_CV_Score', ascending=False).iloc[0]\n",
        "                import ast\n",
        "                try:\n",
        "                    best_hps = ast.literal_eval(best_row['Best_Hyperparameters'])\n",
        "                    if not isinstance(best_hps, dict):\n",
        "                         print(f\"  Warning: Parsed best hyperparameters for {model_name} on {dataset_name} are not a dictionary. Using default HPs.\")\n",
        "                         best_hps = {}\n",
        "                except (ValueError, SyntaxError) as e:\n",
        "                    print(f\"  Error parsing best hyperparameters string for {model_name} on {dataset_name}: {best_row['Best_Hyperparameters']}. Using default HPs. Error: {e}\")\n",
        "                    best_hps = {}\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "\n",
        "        # Use default HPs if not found or loaded incorrectly\n",
        "        if not best_hps:\n",
        "            print(f\"  Using default hyperparameters for {model_name} on {dataset_name}.\")\n",
        "            if model_name == 'CA-LSTM-FCN':\n",
        "                best_hps = {'lstm_hidden_size': 128, 'fcn_filters': [128, 256, 128], 'dropout': 0.2}\n",
        "            elif model_name == 'Transformer':\n",
        "                best_hps = {'d_model': 128, 'nhead': 4, 'num_layers': 3, 'dropout': 0.2}\n",
        "            else:\n",
        "                best_hps = {}\n",
        "        print(f\"  Loaded/Using Hyperparameters: {best_hps}\")\n",
        "\n",
        "\n",
        "        # --- Run 5-fold CV with Best HPs ---\n",
        "        if SPLIT_UNIT == \"segment\":\n",
        "            # Segment-level CV (allows leakage across the same subject by design)\n",
        "            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            cv_splits = list(skf.split(X_mov_train_val, y_train_val))\n",
        "\n",
        "        elif SPLIT_UNIT == \"subject\":\n",
        "            # Subject-level CV: group by subject ID to prevent leakage\n",
        "            patient_ids_all = np.array(dataset_to_evaluate['patient_ids'])\n",
        "            unique_ids = np.unique(patient_ids_all)\n",
        "\n",
        "            # One label per subject (majority vote across their samples)\n",
        "            subject_labels = []\n",
        "            for pid in unique_ids:\n",
        "                mask = (patient_ids_all == pid)\n",
        "                votes = y_train_val[mask]\n",
        "                subject_labels.append(int(np.round(votes.mean())))  # binary case\n",
        "            subject_labels = np.array(subject_labels)\n",
        "\n",
        "            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            subj_splits = list(skf.split(np.zeros(len(unique_ids)), subject_labels))\n",
        "\n",
        "            # Map subject folds back to sample indices\n",
        "            cv_splits = []\n",
        "            for tr_subj_idx, va_subj_idx in subj_splits:\n",
        "                tr_subj_ids = unique_ids[tr_subj_idx]\n",
        "                va_subj_ids = unique_ids[va_subj_idx]\n",
        "                train_idx = np.where(np.isin(patient_ids_all, tr_subj_ids))[0]\n",
        "                val_idx   = np.where(np.isin(patient_ids_all, va_subj_ids))[0]\n",
        "                cv_splits.append((train_idx, val_idx))\n",
        "        else:\n",
        "            raise ValueError(\"SPLIT_UNIT must be 'subject' or 'segment'\")\n",
        "\n",
        "        fold_scores_acc, fold_scores_ba, fold_scores_prec, fold_scores_rec, fold_scores_f1 = [], [], [], [], []\n",
        "\n",
        "        # Map model name string to class\n",
        "        model_class_map = {\n",
        "            'CA-LSTM-FCN': CA_LSTM_FCN,\n",
        "            'Transformer': TimeSeriesTransformer\n",
        "        }\n",
        "\n",
        "        if model_name not in model_class_map:\n",
        "             print(f\"  Skipping unknown model name: {model_name}\")\n",
        "             continue\n",
        "\n",
        "        model_class = model_class_map[model_name]\n",
        "\n",
        "\n",
        "        for fold_idx, (train_idx, val_idx) in enumerate(cv_splits):\n",
        "            # Default: use original arrays\n",
        "            X_mov_tr,  X_quest_tr,  y_tr  = X_mov_train_val, X_quest_train_val, y_train_val\n",
        "            tr_ids = train_idx\n",
        "\n",
        "            # -------- PAPER PARITY: dataset-level cloning --------\n",
        "            if PAPER_PARITY:\n",
        "                y_tr_base = y_train_val[train_idx]\n",
        "                is_neg = (y_tr_base == 0)\n",
        "                neg_idx = train_idx[is_neg]\n",
        "                pos_idx = train_idx[~is_neg]\n",
        "\n",
        "                # Collect originals\n",
        "                X_mov_list   = [X_mov_train_val[pos_idx],   X_mov_train_val[neg_idx]]\n",
        "                X_quest_list = [X_quest_train_val[pos_idx], X_quest_train_val[neg_idx]]\n",
        "                y_list       = [y_train_val[pos_idx],       y_train_val[neg_idx]]\n",
        "\n",
        "                # Build parity-style clones\n",
        "                n_extra = 2 if dataset_to_evaluate['task_type'] == 'pd_vs_hc' else 1  # HC×2 or DD×1\n",
        "                for _ in range(n_extra):\n",
        "                    Xn = X_mov_train_val[neg_idx].copy()\n",
        "                    for i in range(Xn.shape[0]):\n",
        "                        Xn[i] = augmentation.apply_axis_rotation(Xn[i], max_angle=12)\n",
        "                        Xn[i] = augmentation.apply_time_warping(Xn[i], sigma=0.20, knot=4)\n",
        "                    X_mov_list.append(Xn)\n",
        "                    X_quest_list.append(X_quest_train_val[neg_idx])\n",
        "                    y_list.append(y_train_val[neg_idx])\n",
        "\n",
        "                # Concatenate augmented pool\n",
        "                X_mov_tr   = np.concatenate(X_mov_list,   axis=0)\n",
        "                X_quest_tr = np.concatenate(X_quest_list, axis=0)\n",
        "                y_tr       = np.concatenate(y_list,       axis=0)\n",
        "                tr_ids     = np.arange(len(y_tr))  # contiguous indices for dataset\n",
        "            # --------------------------------------------------------------\n",
        "\n",
        "            # ---- fit scalers on TRAIN ONLY (augmented pool if parity) ----\n",
        "            movement_scaler = None\n",
        "            clinical_scaler = None\n",
        "            if modality in ['movement_only', 'combined']:\n",
        "                movement_scaler = StandardScaler()\n",
        "                Xm_fit = X_mov_tr\n",
        "                if Xm_fit.ndim > 2:\n",
        "                    movement_scaler.fit(Xm_fit.reshape(-1, Xm_fit.shape[-1]))\n",
        "                else:\n",
        "                    movement_scaler.fit(Xm_fit)\n",
        "            if modality in ['questionnaire_only', 'combined']:\n",
        "                clinical_scaler = StandardScaler()\n",
        "                clinical_scaler.fit(X_quest_tr)\n",
        "\n",
        "            # ---- datasets ----\n",
        "            train_dataset = TrainingDataset(\n",
        "                X_mov_tr, X_quest_tr, y_tr,\n",
        "                tr_ids, movement_scaler, clinical_scaler,\n",
        "                augmentation if not PAPER_PARITY else None,\n",
        "                is_training=True, modality=modality\n",
        "            )\n",
        "            val_dataset = TrainingDataset(\n",
        "                X_mov_train_val, X_quest_train_val, y_train_val,\n",
        "                val_idx, movement_scaler, clinical_scaler,\n",
        "                None, is_training=False, modality=modality\n",
        "            )\n",
        "\n",
        "\n",
        "            # --- Tell dataset which model is being trained (for augmentation policy) ---\n",
        "            train_dataset.current_model_name = model_name\n",
        "            val_dataset.current_model_name   = model_name\n",
        "\n",
        "            train_dataset.paper_parity = PAPER_PARITY\n",
        "            trainer_single_run.paper_parity = PAPER_PARITY\n",
        "\n",
        "            # --- Instantiate model with BEST HPs ---\n",
        "            # Prepare base parameters needed by all models\n",
        "            params_for_instantiation = {'modality': modality, 'num_classes': 2}\n",
        "\n",
        "            # Add modality-specific input sizes/features and model-specific hyperparameters\n",
        "            if model_name == 'CA-LSTM-FCN':\n",
        "                # Parity: BCE (1 logit) only for segment split\n",
        "                n_classes = 1 if PAPER_PARITY else 2\n",
        "                params_for_instantiation.update({\n",
        "                    'input_channels': X_mov_train_val.shape[-1] if modality in ['movement_only', 'combined'] else 0,\n",
        "                    'questionnaire_features': X_quest_train_val.shape[1] if modality in ['questionnaire_only', 'combined'] else 0,\n",
        "                    'lstm_hidden_size': best_hps.get('lstm_hidden_size'),\n",
        "                    'fcn_filters': best_hps.get('fcn_filters'),\n",
        "                    'dropout': 0.3 if PAPER_PARITY else best_hps.get('dropout'),\n",
        "                    'num_classes': n_classes\n",
        "                })\n",
        "                model = CA_LSTM_FCN(**params_for_instantiation)\n",
        "            elif model_name == 'Transformer':\n",
        "                 # Transformer uses config object\n",
        "                 config = TimeSeriesTransformerConfig(\n",
        "                      modality=modality,\n",
        "                      num_classes=2,\n",
        "                      input_channels=X_mov_train_val.shape[-1] if modality in ['movement_only', 'combined'] else 0,\n",
        "                      questionnaire_features=X_quest_train_val.shape[1] if modality in ['questionnaire_only', 'combined'] else 0,\n",
        "                      d_model=best_hps.get('d_model'),\n",
        "                      nhead=best_hps.get('nhead'),\n",
        "                      num_layers=best_hps.get('num_layers'),\n",
        "                      dropout=best_hps.get('dropout')\n",
        "                 )\n",
        "                 model = TimeSeriesTransformer(config)\n",
        "                 pass\n",
        "\n",
        "            fold_metrics = trainer_single_run.train_single_fold(\n",
        "                model, train_dataset, val_dataset, max_epochs=100, fold_num=fold_idx+1\n",
        "            )\n",
        "\n",
        "            # Collect all best-at-monitor metrics for this fold\n",
        "            fold_scores_acc.append(fold_metrics['best_acc'])\n",
        "            fold_scores_ba.append(fold_metrics['best_ba'])\n",
        "            fold_scores_prec.append(fold_metrics['best_prec'])\n",
        "            fold_scores_rec.append(fold_metrics['best_rec'])\n",
        "            fold_scores_f1.append(fold_metrics['best_f1'])\n",
        "\n",
        "            # single-line fold summary\n",
        "            print(f\"[Fold {fold_idx+1}] Acc={fold_metrics['best_acc']:.4f}  \"\n",
        "                  f\"BA={fold_metrics['best_ba']:.4f}  Prec={fold_metrics['best_prec']:.4f}  \"\n",
        "                  f\"Rec={fold_metrics['best_rec']:.4f}  F1={fold_metrics['best_f1']:.4f}  \"\n",
        "                  f\"(best epoch {fold_metrics['best_epoch']})\")\n",
        "\n",
        "            if 'all_fold_metrics' not in locals():\n",
        "                all_fold_metrics = []\n",
        "            all_fold_metrics.append(fold_metrics)\n",
        "\n",
        "\n",
        "            # cleanup\n",
        "            del model\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "            else:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        mean_acc  = float(np.mean(fold_scores_acc));  std_acc  = float(np.std(fold_scores_acc))\n",
        "        mean_ba   = float(np.mean(fold_scores_ba));   std_ba   = float(np.std(fold_scores_ba))\n",
        "        mean_prec = float(np.mean(fold_scores_prec)); std_prec = float(np.std(fold_scores_prec))\n",
        "        mean_rec  = float(np.mean(fold_scores_rec));  std_rec  = float(np.std(fold_scores_rec))\n",
        "        mean_f1   = float(np.mean(fold_scores_f1));   std_f1   = float(np.std(fold_scores_f1))\n",
        "\n",
        "        print(f\"\\n  Results for {model_name} on {dataset_name}:\")\n",
        "        print(f\"    Acc={mean_acc:.4f}±{std_acc:.4f}  BA={mean_ba:.4f}±{std_ba:.4f}\")\n",
        "        print(f\"    Prec={mean_prec:.4f}±{std_prec:.4f}  Rec={mean_rec:.4f}±{std_rec:.4f}  F1={mean_f1:.4f}±{std_f1:.4f}\")\n",
        "        print(f\"    Per-Fold metrics:\")\n",
        "        print(f\"      Acc:  {np.round(fold_scores_acc, 4).tolist()}\")\n",
        "        print(f\"      BA:   {np.round(fold_scores_ba, 4).tolist()}\")\n",
        "        print(f\"      Prec: {np.round(fold_scores_prec, 4).tolist()}\")\n",
        "        print(f\"      Rec:  {np.round(fold_scores_rec, 4).tolist()}\")\n",
        "        print(f\"      F1:   {np.round(fold_scores_f1, 4).tolist()}\")\n",
        "\n",
        "        all_best_hp_results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'Model': model_name,\n",
        "            'Hyperparameters': best_hps,\n",
        "            'Mean_CV_Acc': mean_acc,  'Std_CV_Acc': std_acc,\n",
        "            'Mean_CV_BA': mean_ba,    'Std_CV_BA': std_ba,\n",
        "            'Mean_CV_Prec': mean_prec,'Std_CV_Prec': std_prec,\n",
        "            'Mean_CV_Rec': mean_rec,  'Std_CV_Rec': std_rec,\n",
        "            'Mean_CV_F1': mean_f1,    'Std_CV_F1': std_f1,\n",
        "            'Fold_Acc_Scores': fold_scores_acc,\n",
        "            'Fold_BA_Scores': fold_scores_ba,\n",
        "            'Fold_Prec_Scores': fold_scores_prec,\n",
        "            'Fold_Rec_Scores': fold_scores_rec,\n",
        "            'Fold_F1_Scores': fold_scores_f1\n",
        "        })\n",
        "\n",
        "# --- Final Summary of Best HP Results ---\n",
        "print(\"\\n===== Summary of Evaluation with Best Hyperparameters =====\")\n",
        "if all_best_hp_results:\n",
        "    best_hp_results_df = pd.DataFrame(all_best_hp_results)\n",
        "    # Display results sorted by Mean CV Balanced Accuracy\n",
        "    display(best_hp_results_df.sort_values('Mean_CV_BA', ascending=False))\n",
        "\n",
        "    # Save these results to a separate summary file\n",
        "    best_hp_results_df.to_csv(RESULTS_DIR / 'framework1_subjectlevel_results.csv', index=False)\n",
        "    print(f\"\\nSummary saved to: {RESULTS_DIR / 'framework1_subjectlevel_results.csv'}\")\n",
        "else:\n",
        "    print(\"No evaluation results were generated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r5fpUvW5lZW"
      },
      "source": [
        "### Framework 1 Result Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sakzip84BSMx",
        "outputId": "ace49800-bade-44d1-9342-44da1a7dd91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing Results:\n",
            "Saving grouped model scores to: /content/drive/MyDrive/pads/results/grouped_model_scores.txt\n",
            "Loaded results from: /content/drive/MyDrive/pads/results/calstmfcn_segment_paperparity.csv\n",
            "\n",
            "Analyzing Pd Vs Hc Movement Only...\n",
            "    CA-LSTM-FCN: 0.7905\n",
            "\n",
            "Analyzing Pd Vs Hc Questionnaire Only...\n",
            "    CA-LSTM-FCN: 0.9802\n",
            "\n",
            "Analyzing Pd Vs Hc Combined...\n",
            "    CA-LSTM-FCN: 0.9993\n",
            "\n",
            "Analyzing Pd Vs Dd Movement Only...\n",
            "    CA-LSTM-FCN: 0.7488\n",
            "\n",
            "Analyzing Pd Vs Dd Questionnaire Only...\n",
            "    CA-LSTM-FCN: 0.9890\n",
            "\n",
            "Analyzing Pd Vs Dd Combined...\n",
            "    CA-LSTM-FCN: 0.9991\n",
            "\n",
            "Analysis complete!\n"
          ]
        }
      ],
      "source": [
        "# def analyze_results():\n",
        "#     print(\"Analyzing Results:\")\n",
        "#     desired_order = [\n",
        "#         'pd_vs_hc_movement_only',\n",
        "#         'pd_vs_hc_questionnaire_only',\n",
        "#         'pd_vs_hc_combined',\n",
        "#         'pd_vs_dd_movement_only',\n",
        "#         'pd_vs_dd_questionnaire_only',\n",
        "#         'pd_vs_dd_combined'\n",
        "#     ]\n",
        "\n",
        "#     # Define the path for the output file\n",
        "#     output_filename = \"grouped_model_scores.txt\"\n",
        "#     output_filepath = RESULTS_DIR / output_filename\n",
        "\n",
        "#     print(f\"Saving grouped model scores to: {output_filepath}\")\n",
        "\n",
        "#     # Load the results from the new CSV file\n",
        "#     new_results_csv_path = RESULTS_DIR / 'calstmfcn_segment_paperparity.csv'\n",
        "#     try:\n",
        "#         results_df_analysis = pd.read_csv(new_results_csv_path)\n",
        "#         print(f\"Loaded results from: {new_results_csv_path}\")\n",
        "#     except FileNotFoundError:\n",
        "#         print(f\"Error: Results CSV not found at {new_results_csv_path}. Cannot perform analysis.\")\n",
        "#         return {} # Return empty dictionary if file not found\n",
        "\n",
        "#     # Reconstruct the all_results dictionary structure from the DataFrame\n",
        "#     # Assuming the DataFrame has columns: 'Dataset', 'Model', 'Mean_CV_BA', 'Std_CV_BA'\n",
        "#     all_results_analysis = {}\n",
        "#     for index, row in results_df_analysis.iterrows():\n",
        "#         dataset_name = row['Dataset']\n",
        "#         model_name = row['Model']\n",
        "#         mean_score = row['Mean_CV_BA']\n",
        "#         std_score = row['Std_CV_BA']\n",
        "\n",
        "#         if dataset_name not in all_results_analysis:\n",
        "#             all_results_analysis[dataset_name] = {}\n",
        "\n",
        "#         all_results_analysis[dataset_name][model_name] = {\n",
        "#             'mean_cv_score': mean_score,\n",
        "#             'std_cv_score': std_score,\n",
        "#             # Add other relevant fields if needed, based on the original structure\n",
        "#         }\n",
        "\n",
        "\n",
        "#     analysis = {}\n",
        "\n",
        "#     with open(output_filepath, 'w') as f:\n",
        "#         f.write(\"Analyzing Results:\\n\")\n",
        "\n",
        "#         for dataset_name in desired_order:\n",
        "#             # Check if the dataset exists in the loaded results\n",
        "#             if dataset_name in all_results_analysis:\n",
        "#                 task_results = all_results_analysis[dataset_name]\n",
        "\n",
        "#                 display_name = dataset_name.replace('_vs_', ' vs ').replace('_', ' ').title()\n",
        "#                 print(f\"\\nAnalyzing {display_name}...\")\n",
        "#                 f.write(f\"\\nAnalyzing {display_name}...\\n\")\n",
        "\n",
        "#                 best_model = None\n",
        "#                 best_cv_score = -1.0\n",
        "\n",
        "#                 # Iterate through models for the current dataset\n",
        "#                 for model_name, result in task_results.items():\n",
        "#                     cv_score = result['mean_cv_score']\n",
        "\n",
        "#                     print(f\"    {model_name}: {cv_score:.4f}\")\n",
        "#                     f.write(f\"    {model_name}: {cv_score:.4f}\\n\")\n",
        "\n",
        "#                     if cv_score > best_cv_score:\n",
        "#                         best_cv_score = cv_score\n",
        "#                         best_model = model_name\n",
        "#         print(\"\\nAnalysis complete!\")\n",
        "#         f.write(\"\\nAnalysis complete!\\n\")\n",
        "#     return analysis\n",
        "\n",
        "# # Call the analyze_results function to perform the analysis and generate the output file\n",
        "# analysis_results = analyze_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e72dc2f8"
      },
      "source": [
        "## Framework 2: (Task-based Movement)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRDJTFiX57He"
      },
      "source": [
        "### Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "dLuASzHlB0Wh",
        "outputId": "b77aacd8-a47d-4402-fea9-7afef0fb59f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Scenario: pd_vs_hc — TaskSet: 11 tasks =====\n",
            "[info] Loaded label map for 469 subjects.\n",
            "[HPs] pd_vs_hc Transformer: {'d_model': 256, 'nhead': 8, 'num_layers': 2, 'dropout': 0.2}\n",
            "\n",
            "=== [pd_vs_hc] TaskFusion[11] — Transformer : Fold 1/5, epochs=60 ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1675447127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;31m# 2) PD vs HC with ALL tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m df_hc_all = run_scenario_latefusion(\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0mscenario_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pd_vs_hc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mlabel_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1675447127.py\u001b[0m in \u001b[0;36mrun_scenario_latefusion\u001b[0;34m(scenario_name, label_keep, label_remap, hp_scenario_substr, task_set, model_name)\u001b[0m\n\u001b[1;32m    587\u001b[0m               f\"Fold {fold_idx}/5, epochs={epochs} ===\")\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         best_ba, best_acc, best_prec, best_rec, best_f1 = trainer.train_single_fold(\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         )\n",
            "\u001b[0;32m/tmp/ipython-input-1675447127.py\u001b[0m in \u001b[0;36mtrain_single_fold\u001b[0;34m(self, model, train_loader, val_loader, max_epochs, fold_num)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mtrain_loss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                 \u001b[0mtrain_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# === Transformer (movement-only), PD-vs-HC and PD-vs-DD ===\n",
        "# Loads preprocessed /movement *.bin files, builds per-subject multi-task packs,\n",
        "# trains with fusion across tasks\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "HP_CSV_PATH  = RESULTS_DIR / 'evaluation_results_with_hp_tuning.csv'\n",
        "\n",
        "TASKS  = [\"Relaxed1\",\"Relaxed2\",\"RelaxedTask1\",\"RelaxedTask2\",\"StretchHold\",\n",
        "          \"HoldWeight\",\"DrinkGlas\",\"CrossArms\",\"TouchNose\",\"Entrainment1\",\"Entrainment2\"]\n",
        "WRISTS = [\"Left\", \"Right\"]\n",
        "SENSORS= [\"Accelerometer\",\"Gyroscope\"]\n",
        "AXES   = [\"X\",\"Y\",\"Z\"]\n",
        "TARGET_T = 950\n",
        "QUESTIONNAIRE_F = 30          # placeholder (unused in movement_only)\n",
        "MAX_EPOCHS = 40\n",
        "SCENARIO_EPOCHS = {\"pd_vs_hc\": 60, \"pd_vs_dd\": 60}\n",
        "SEED = 42\n",
        "\n",
        "# ---- EXPERIMENT KNOBS ----\n",
        "# best tasks set\n",
        "FOCUS_TASKS = [\"HoldWeight\",\"RelaxedTask2\",\"Entrainment1\",\"Relaxed1\",\"StretchHold\",\"TouchNose\",\"DrinkGlas\"]\n",
        "\n",
        "# Choose the sensor fusion mode across wrists\n",
        "#   \"acc_gyro_both_wrists\" -> [T, 12]\n",
        "#   \"acc_only_both_wrists\" -> [T, 6]\n",
        "#   \"full_132\" -> [T, 132]\n",
        "EXPERIMENT_MODE = \"acc_gyro_both_wrists\"\n",
        "\n",
        "# ---------- DEVICE / REPRO ----------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ---------- SMALL UTILS ----------\n",
        "# ---- Augmentation helpers ----\n",
        "class OnTheFlyAugmentation:\n",
        "    \"\"\"Rotate each 3-axis triplet; (optionally) time-warp. Works for C=6 or 12 or 132.\"\"\"\n",
        "    def __init__(self, rot_p=0.30, rot_deg=5, warp_p=0.0, warp_sigma=0.10, warp_knot=4):\n",
        "        self.rot_p = float(rot_p)\n",
        "        self.rot_deg = float(rot_deg)\n",
        "        self.warp_p = float(warp_p)          # keep 0.0 to disable time warping\n",
        "        self.warp_sigma = float(warp_sigma)\n",
        "        self.warp_knot = int(warp_knot)\n",
        "\n",
        "    def _rotation_matrix_3d(self, angle_deg):\n",
        "        ang = np.radians(angle_deg)\n",
        "        axis = np.random.choice(['x','y','z'])\n",
        "        c, s = np.cos(ang), np.sin(ang)\n",
        "        if axis == 'x':\n",
        "            R = np.array([[1,0,0],[0,c,-s],[0,s,c]], dtype=np.float32)\n",
        "        elif axis == 'y':\n",
        "            R = np.array([[c,0,s],[0,1,0],[-s,0,c]], dtype=np.float32)\n",
        "        else:\n",
        "            R = np.array([[c,-s,0],[s,c,0],[0,0,1]], dtype=np.float32)\n",
        "        return R\n",
        "\n",
        "    def apply_axis_rotation(self, data, max_angle=15):\n",
        "        \"\"\"\n",
        "        Rotate per wrist. If gyro is present, use the same R for that wrist's acc+gyro.\n",
        "        data: [T, C] with C in {6, 12} given your EXPERIMENT_MODE.\n",
        "        \"\"\"\n",
        "        x = data.copy()\n",
        "        T, C = x.shape\n",
        "\n",
        "        def rot_block(start, length, R):\n",
        "            # rotate channels [start:start+length] interpreted as stacked 3D vectors\n",
        "            assert length % 3 == 0\n",
        "            for i in range(start, start + length, 3):\n",
        "                x[:, i:i+3] = (R @ x[:, i:i+3].T).T\n",
        "\n",
        "        if C == 12:\n",
        "            # Left wrist (acc 0:3, gyro 3:6)\n",
        "            R_L = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "            rot_block(0, 3, R_L)   # accL\n",
        "            rot_block(3, 3, R_L)   # gyrL (same R as accL)\n",
        "\n",
        "            # Right wrist (acc 6:9, gyro 9:12)\n",
        "            R_R = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "            rot_block(6, 3, R_R)   # accR\n",
        "            rot_block(9, 3, R_R)   # gyrR (same R as accR)\n",
        "\n",
        "        elif C == 6:\n",
        "            # Acc only, rotate each wrist independently\n",
        "            R_L = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "            rot_block(0, 3, R_L)   # accL\n",
        "\n",
        "            R_R = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "            rot_block(3, 3, R_R)   # accR\n",
        "        elif C == 132:\n",
        "            # 11 tasks × (Left/Right × Acc/Gyro × 3 axes) = 132\n",
        "            stride = 12  # channels per task block\n",
        "            # one R per wrist (consistent across all tasks, like 12-ch old path)\n",
        "            R_L = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "            R_R = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "            for t_idx in range(len(TASKS)):\n",
        "                base = t_idx * stride\n",
        "                # Left wrist: acc (0:3), gyro (3:6)\n",
        "                for off in (0, 3):\n",
        "                    x[:, base+off:base+off+3] = (R_L @ x[:, base+off:base+off+3].T).T\n",
        "                # Right wrist: acc (6:9), gyro (9:12)\n",
        "                for off in (6, 9):\n",
        "                    x[:, base+off:base+off+3] = (R_R @ x[:, base+off:base+off+3].T).T\n",
        "        else:\n",
        "            # Fallback: rotate each 3-axis triplet\n",
        "            for s in range(0, C, 3):\n",
        "                if s + 3 <= C:\n",
        "                    R = self._rotation_matrix_3d(np.random.uniform(-max_angle, max_angle))\n",
        "                    rot_block(s, 3, R)\n",
        "\n",
        "        return x.astype(np.float32, copy=False)\n",
        "\n",
        "\n",
        "    def apply_time_warping(self, data, sigma=0.2, knot=4):\n",
        "        T, C = data.shape\n",
        "        orig = np.arange(T)\n",
        "        # smooth monotonic warp\n",
        "        random_warps = np.abs(np.random.normal(loc=1.0, scale=sigma, size=(knot+2,)))\n",
        "        time_warp = np.cumsum(random_warps)\n",
        "        time_warp = time_warp / time_warp[-1] * (T - 1)\n",
        "        warp_steps = np.linspace(0, T - 1, num=knot+2)\n",
        "        idx = np.interp(orig, warp_steps, time_warp).clip(0, T - 1)\n",
        "\n",
        "        y = np.empty_like(data)\n",
        "        for i in range(C):\n",
        "            y[:, i] = np.interp(idx, orig, data[:, i])\n",
        "        return y.astype(np.float32, copy=False)\n",
        "\n",
        "    def apply_random_augmentation(self, data):\n",
        "        x = data.copy()\n",
        "        if np.random.rand() < self.rot_p:\n",
        "            x = self.apply_axis_rotation(x, max_angle=self.rot_deg)\n",
        "        if np.random.rand() < self.warp_p:\n",
        "            x = self.apply_time_warping(x, sigma=self.warp_sigma, knot=self.warp_knot)\n",
        "        return x.astype(np.float32, copy=False)\n",
        "\n",
        "def _clean_name(s):\n",
        "    return re.sub(r\"[^A-Za-z0-9]+\", \"\", s)\n",
        "\n",
        "def parse_hps(x):\n",
        "    if not isinstance(x, str): return x\n",
        "    try:\n",
        "        return ast.literal_eval(x)\n",
        "    except Exception:\n",
        "        s = x.replace(\"None\",\"null\").replace(\"True\",\"true\").replace(\"False\",\"false\")\n",
        "        if \"'\" in s and '\"' not in s: s = re.sub(r\"'\", '\"', s)\n",
        "        return json.loads(s)\n",
        "\n",
        "def _mode_input_channels():\n",
        "    if EXPERIMENT_MODE == \"acc_gyro_both_wrists\": return 12\n",
        "    if EXPERIMENT_MODE == \"acc_only_both_wrists\": return 6\n",
        "    if EXPERIMENT_MODE == \"full_132\": return 132\n",
        "    raise ValueError(f\"Unsupported EXPERIMENT_MODE={EXPERIMENT_MODE} for late fusion\")\n",
        "\n",
        "def _sensor_label_for_results():\n",
        "    return {\n",
        "        \"acc_gyro_both_wrists\": \"Accel+Gyro (BothWrists)\",\n",
        "        \"acc_only_both_wrists\": \"Accelerometer (BothWrists)\",\n",
        "        \"full_132\": \"AllTasks_AllSensors_BothWrists_132ch\",\n",
        "    }[EXPERIMENT_MODE].replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
        "\n",
        "def subject_id_from_filename(path):\n",
        "    base = os.path.basename(path)\n",
        "    m = re.findall(r\"\\d+\", base)\n",
        "    return int(m[0].lstrip(\"0\") or \"0\") if m else None\n",
        "\n",
        "def head_trim_to_T(x, target_T=950):\n",
        "    \"\"\"Trim from the START so we drop the waiting period, then pad at the END if needed.\"\"\"\n",
        "    T = x.shape[0]\n",
        "    if T == target_T:\n",
        "        return x\n",
        "    if T > target_T:\n",
        "        drop = T - target_T\n",
        "        return x[drop:, :][:target_T]\n",
        "    # shorter -> pad at the END\n",
        "    pad = target_T - T\n",
        "    return np.pad(x, ((0, pad), (0, 0)), mode=\"constant\")\n",
        "\n",
        "def load_subject_bin_multiindex(path, TASKS, WRISTS, SENSORS, AXES):\n",
        "    arr = np.fromfile(path, dtype=np.float32)\n",
        "    assert arr.size % 132 == 0, f\"Unexpected float count in {os.path.basename(path)}\"\n",
        "    T = arr.size // 132\n",
        "    data = arr.reshape(T, 132)  # [T, C]\n",
        "    cols = pd.MultiIndex.from_product([TASKS, WRISTS, SENSORS, AXES],\n",
        "                                      names=[\"task\",\"wrist\",\"sensor\",\"axis\"])\n",
        "    df = pd.DataFrame(data, columns=cols)\n",
        "    return df\n",
        "\n",
        "def load_full_label_map():\n",
        "    assert os.path.exists(LABELS_CSV), f\"Missing LABELS_CSV: {LABELS_CSV}\"\n",
        "    df = pd.read_csv(LABELS_CSV)\n",
        "    assert {\"id\",\"label\"}.issubset(df.columns), \"file_list.csv must contain 'id' and 'label'.\"\n",
        "    df = df.copy()\n",
        "    df[\"id\"] = df[\"id\"].astype(str).str.extract(r\"(\\d+)\").astype(int)\n",
        "    lab = dict(zip(df[\"id\"].astype(int), df[\"label\"].astype(int)))\n",
        "    print(f\"[info] Loaded label map for {len(lab)} subjects.\")\n",
        "    return lab\n",
        "\n",
        "hp_df = pd.read_csv(HP_CSV_PATH)\n",
        "CSV_ALIASES = {\n",
        "    \"Transformer\":   [\"Transformer\",\"Transformer-EarlyFusion\"],\n",
        "    \"CA_LSTM_FCN\":   [\"CA_LSTM_FCN\",\"CA-LSTM-FCN\",\"CALSTMFCN\",\"CA_LSTM+FCN\"]\n",
        "}\n",
        "def best_hps_for(model_name, scenario_substr=None):\n",
        "    names = CSV_ALIASES.get(model_name, [model_name])\n",
        "    df = hp_df[hp_df[\"Model\"].isin(names)]\n",
        "    if scenario_substr:\n",
        "        dff = df[df[\"Dataset\"].str.contains(scenario_substr, case=False, na=False)]\n",
        "        if not dff.empty:\n",
        "            df = dff\n",
        "    if df.empty:\n",
        "        # No tuned HPs for this model/scenario -> use model defaults\n",
        "        return {}\n",
        "    row = df.sort_values(by=\"Mean_CV_Score\", ascending=False).iloc[0]\n",
        "    return parse_hps(row[\"Best_Hyperparameters\"])\n",
        "\n",
        "def make_class_weights(y_train: np.ndarray, num_classes: int = 2) -> torch.Tensor:\n",
        "    counts = np.bincount(y_train, minlength=num_classes).astype(float)\n",
        "    counts[counts == 0] = 1.0\n",
        "    inv = 1.0 / counts\n",
        "    w = inv / inv.sum() * num_classes\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "# ----------- MODEL BUILDER -----------\n",
        "def build_model_transformer(hps, modality=\"movement_only\"):\n",
        "    in_ch = _mode_input_channels()\n",
        "    tuned_hps = dict(hps or {})\n",
        "    if modality == \"movement_only\":\n",
        "        # slightly beefier defaults for 132ch\n",
        "        tuned_hps.setdefault(\"d_model\", 192 if in_ch == 132 else 128)\n",
        "        tuned_hps.setdefault(\"nhead\", 6 if in_ch == 132 else 4)\n",
        "        tuned_hps.setdefault(\"num_layers\", 4)\n",
        "        tuned_hps.setdefault(\"dropout\", 0.20)\n",
        "    tuned_hps.setdefault(\"num_classes\", 2)\n",
        "    cfg = TimeSeriesTransformerConfig(\n",
        "        modality=modality,\n",
        "        sequence_length=TARGET_T,\n",
        "        input_channels=in_ch,\n",
        "        questionnaire_features=QUESTIONNAIRE_F,\n",
        "        **tuned_hps\n",
        "    )\n",
        "    return TimeSeriesTransformer(cfg)\n",
        "\n",
        "def build_model_ca_lstm_fcn(hps, modality=\"movement_only\"):\n",
        "    in_ch = _mode_input_channels()\n",
        "    tuned = {\n",
        "        \"input_channels\": in_ch,\n",
        "        \"sequence_length\": TARGET_T,\n",
        "        \"num_classes\": 2,\n",
        "        \"questionnaire_features\": QUESTIONNAIRE_F,\n",
        "        \"lstm_hidden_size\": hps.get(\"lstm_hidden_size\", 128),\n",
        "        \"fcn_filters\": hps.get(\"fcn_filters\", [128, 256, 128]),\n",
        "        \"dropout\": hps.get(\"dropout\", 0.2),\n",
        "        \"modality\": modality,\n",
        "    }\n",
        "    return CA_LSTM_FCN(**tuned)\n",
        "\n",
        "# ----------- DATA PACKING -----------\n",
        "def build_per_subject_taskpack(subjects, label_map, task_set):\n",
        "    packs = []\n",
        "    for sid, p in subjects:\n",
        "        if sid not in label_map:\n",
        "            continue\n",
        "        df = load_subject_bin_multiindex(p, TASKS, WRISTS, SENSORS, AXES)\n",
        "        y  = int(label_map[sid])\n",
        "\n",
        "        # --- PAPER / 132ch path: one block per subject ---\n",
        "        if EXPERIMENT_MODE == \"full_132\":\n",
        "            X = df.to_numpy().astype(np.float32)\n",
        "            X = head_trim_to_T(X, TARGET_T)\n",
        "            if not np.isnan(X).any():\n",
        "                packs.append({\"sid\": sid, \"y\": y, \"tasks\": {\"ALL\": X}})\n",
        "            continue\n",
        "\n",
        "        # --- Original 6/12-ch late-fusion path ---\n",
        "        task_dict = {}\n",
        "        for task in task_set:\n",
        "            if EXPERIMENT_MODE == \"acc_gyro_both_wrists\":\n",
        "                accL = df[(task, \"Left\",  \"Accelerometer\")].to_numpy()\n",
        "                gyrL = df[(task, \"Left\",  \"Gyroscope\")].to_numpy()\n",
        "                accR = df[(task, \"Right\", \"Accelerometer\")].to_numpy()\n",
        "                gyrR = df[(task, \"Right\", \"Gyroscope\")].to_numpy()\n",
        "                X = np.concatenate([accL, gyrL, accR, gyrR], axis=1)  # [T,12]\n",
        "            elif EXPERIMENT_MODE == \"acc_only_both_wrists\":\n",
        "                accL = df[(task, \"Left\",  \"Accelerometer\")].to_numpy()\n",
        "                accR = df[(task, \"Right\", \"Accelerometer\")].to_numpy()\n",
        "                X = np.concatenate([accL, accR], axis=1)              # [T,6]\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected mode\")\n",
        "            X = head_trim_to_T(X, TARGET_T).astype(np.float32)\n",
        "            if not np.isnan(X).any():\n",
        "                task_dict[task] = X\n",
        "\n",
        "        if len(task_dict) > 0:\n",
        "            packs.append({\"sid\": sid, \"y\": y, \"tasks\": task_dict})\n",
        "    return packs\n",
        "\n",
        "\n",
        "# ----------- DATASETS -----------\n",
        "class MultiTaskDataset(Dataset):\n",
        "    \"\"\"\n",
        "    For training: sample_one_task=True -> (x[T,C], zeros, y) with optional augmentation.\n",
        "    For eval:     sample_one_task=False -> (x_stack[num_tasks,T,C], mask[num_tasks], y)\n",
        "    \"\"\"\n",
        "    def __init__(self, subject_packs, task_list, sample_one_task: bool,\n",
        "                 augmentor=None, is_training: bool=False, aug_prob: float=0.35):\n",
        "        self.packs = subject_packs\n",
        "        self.task_list = list(task_list)  # fixed order for stacking\n",
        "        self.sample_one = bool(sample_one_task)\n",
        "        self.augmentor = augmentor\n",
        "        self.is_training = bool(is_training)\n",
        "        self.aug_prob = float(aug_prob)\n",
        "\n",
        "    def __len__(self): return len(self.packs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pack = self.packs[idx]\n",
        "        y = int(pack[\"y\"])\n",
        "\n",
        "        if self.sample_one:\n",
        "            t = next(iter(pack[\"tasks\"])) if len(pack[\"tasks\"]) == 1 else random.choice(list(pack[\"tasks\"].keys()))\n",
        "            x = pack[\"tasks\"][t]\n",
        "\n",
        "            if self.is_training and (self.augmentor is not None) and (self.aug_prob > 0) \\\n",
        "              and (np.random.rand() < self.aug_prob) \\\n",
        "              and hasattr(self.augmentor, \"apply_random_augmentation\"):\n",
        "                x = self.augmentor.apply_random_augmentation(x)\n",
        "\n",
        "            return torch.from_numpy(x), torch.zeros(QUESTIONNAIRE_F, dtype=torch.float32), y\n",
        "\n",
        "        # eval: stack all tasks (no augmentation)\n",
        "        xs, mask = [], []\n",
        "        for t in self.task_list:\n",
        "            if t in pack[\"tasks\"]:\n",
        "                xs.append(torch.from_numpy(pack[\"tasks\"][t]))\n",
        "                mask.append(1.0)\n",
        "            else:\n",
        "                xs.append(torch.zeros(TARGET_T, _mode_input_channels(), dtype=torch.float32))\n",
        "                mask.append(0.0)\n",
        "        x_stack = torch.stack(xs, dim=0)\n",
        "        mask = torch.tensor(mask, dtype=torch.float32)\n",
        "        return x_stack, mask, y\n",
        "\n",
        "# ----------- TRAINER -----------\n",
        "class LateFusionTrainer:\n",
        "    def __init__(self, device=\"cpu\", class_weights=None, label_smoothing=0.05, lr=5e-4, verbose_every=1):\n",
        "        self.device = device\n",
        "        self.class_weights = class_weights\n",
        "        self.label_smoothing = float(label_smoothing)\n",
        "        self.lr = float(lr)\n",
        "        self.verbose_every = int(verbose_every)\n",
        "\n",
        "    def _criterion(self):\n",
        "        alpha = self.class_weights.to(self.device) if self.class_weights is not None else None\n",
        "        return nn.CrossEntropyLoss(weight=alpha, label_smoothing=self.label_smoothing)\n",
        "\n",
        "    def train_single_fold(self, model, train_loader, val_loader, max_epochs, fold_num):\n",
        "        model = model.to(self.device)\n",
        "        opt = optim.AdamW(model.parameters(), lr=self.lr, weight_decay=5e-4)\n",
        "        sch = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max_epochs)\n",
        "        crit = self._criterion()\n",
        "\n",
        "        best_state = None\n",
        "        patience = 30\n",
        "        bad = 0\n",
        "        best_pack = {\"ba\": 0.0, \"acc\": 0.0, \"prec\": 0.0, \"rec\": 0.0, \"f1\": 0.0}\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            # ----------------- TRAIN -----------------\n",
        "            model.train()\n",
        "            train_loss_sum = 0.0\n",
        "            train_batches = 0\n",
        "            for x, _, y in train_loader:  # (x[T,C], zeros, y)\n",
        "                x = x.to(self.device, dtype=torch.float32)          # [B,T,C]\n",
        "                y_t = torch.as_tensor(y, device=self.device)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                zeros_q = torch.zeros(x.size(0), QUESTIONNAIRE_F, device=self.device)\n",
        "                logits = model(x, zeros_q)                           # [B,num_classes]\n",
        "                loss = crit(logits, y_t.long())\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                opt.step()\n",
        "\n",
        "                train_loss_sum += float(loss.detach().cpu().item())\n",
        "                train_batches += 1\n",
        "\n",
        "            # ----------------- VALID -----------------\n",
        "            model.eval()\n",
        "            y_true, y_pred = [], []\n",
        "            val_loss_sum = 0.0\n",
        "            val_batches = 0\n",
        "            with torch.no_grad():\n",
        "                for x_stack, mask, y in val_loader:\n",
        "                    B, K, _, _ = x_stack.shape\n",
        "                    x_stack = x_stack.to(self.device, dtype=torch.float32)\n",
        "                    mask = mask.to(self.device, dtype=torch.float32)\n",
        "                    y_t = torch.as_tensor(y, device=self.device)\n",
        "\n",
        "                    logits_tasks = []\n",
        "                    active_idx = []\n",
        "                    for k in range(K):\n",
        "                        if mask[:, k].sum().item() == 0:\n",
        "                            continue\n",
        "                        xk = x_stack[:, k, :, :]\n",
        "                        zeros_q = torch.zeros(B, QUESTIONNAIRE_F, device=self.device)\n",
        "                        lk = model(xk, zeros_q)                      # [B,C]\n",
        "                        logits_tasks.append(lk.unsqueeze(1))         # [B,1,C]\n",
        "                        active_idx.append(k)\n",
        "\n",
        "                    if not logits_tasks:\n",
        "                        continue\n",
        "\n",
        "                    logits_tasks = torch.cat(logits_tasks, dim=1)    # [B,K',C]\n",
        "                    mask_active = mask[:, active_idx]                 # [B,K']\n",
        "\n",
        "                    gate = logits_tasks.mean(-1)                      # [B,K']\n",
        "                    gate = gate.masked_fill(mask_active == 0, float('-inf'))\n",
        "                    att  = torch.softmax(gate, dim=1)                 # [B,K']\n",
        "                    fused = (logits_tasks * att.unsqueeze(-1)).sum(dim=1)  # [B,C]\n",
        "\n",
        "                    # accumulate val loss on fused logits\n",
        "                    vloss = crit(fused, y_t.long())\n",
        "                    val_loss_sum += float(vloss.detach().cpu().item())\n",
        "                    val_batches += 1\n",
        "\n",
        "                    preds = fused.argmax(dim=1)\n",
        "                    y_pred.extend(preds.detach().cpu().numpy().tolist())\n",
        "                    y_true.extend(y.detach().cpu().numpy().tolist())\n",
        "\n",
        "            # Metrics\n",
        "            y_true_np = np.array(y_true)\n",
        "            y_pred_np = np.array(y_pred)\n",
        "            ba = balanced_accuracy_score(y_true_np, y_pred_np) if len(y_true_np) else 0.0\n",
        "            acc = (y_true_np == y_pred_np).mean() if len(y_true_np) else 0.0\n",
        "            prec = precision_score(y_true_np, y_pred_np, zero_division=0) if len(y_true_np) else 0.0\n",
        "            rec  = recall_score(y_true_np, y_pred_np, zero_division=0) if len(y_true_np) else 0.0\n",
        "            f1   = f1_score(y_true_np, y_pred_np, zero_division=0) if len(y_true_np) else 0.0\n",
        "\n",
        "            sch.step()\n",
        "\n",
        "            # Early stopping on BA; remember all metrics at the best-BA epoch\n",
        "            if ba > best_pack[\"ba\"]:\n",
        "                best_pack.update({\"ba\": ba, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1})\n",
        "                bad = 0\n",
        "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            else:\n",
        "                bad += 1\n",
        "\n",
        "            # ---- Logging cadence ----\n",
        "            if (epoch < 3) or ((epoch + 1) % self.verbose_every == 0):\n",
        "                tl = train_loss_sum / max(1, train_batches)\n",
        "                vl = val_loss_sum / max(1, val_batches)\n",
        "                print(\n",
        "                    f\"    Fold {fold_num}, Epoch {epoch+1:3d}: \"\n",
        "                    f\"TrainLoss={tl:.4f} | ValLoss={vl:.4f} | \"\n",
        "                    f\"BalAcc={ba:.4f} | Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f} | F1={f1:.4f}\"\n",
        "                )\n",
        "\n",
        "            if bad >= patience:\n",
        "                print(f\"    Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        if best_state is not None:\n",
        "            model.load_state_dict(best_state)\n",
        "        return best_pack[\"ba\"], best_pack[\"acc\"], best_pack[\"prec\"], best_pack[\"rec\"], best_pack[\"f1\"]\n",
        "\n",
        "# ----------- MAIN SCENARIO RUN  -----------\n",
        "def run_scenario_latefusion(scenario_name, label_keep, label_remap, hp_scenario_substr, task_set,model_name=\"Transformer\"):\n",
        "    print(f\"\\n===== Scenario: {scenario_name} — TaskSet: {len(task_set)} tasks =====\")\n",
        "    # --- precompute names used by both CSV and ckpt paths ---\n",
        "    sensor_label = _sensor_label_for_results()\n",
        "    task_tag = (\n",
        "        \"besttasks\" if set(task_set) == set(FOCUS_TASKS)\n",
        "        else (\"alltasks\" if set(task_set) == set(TASKS) else f\"{len(task_set)}tasks\")\n",
        "    )\n",
        "\n",
        "    # Discover subjects\n",
        "    bin_paths = sorted(glob.glob(os.path.join(MOVEMENT_DIR, \"*.bin\")))\n",
        "    assert bin_paths, f\"No .bin files found in {MOVEMENT_DIR}\"\n",
        "    full_label_map = load_full_label_map()\n",
        "\n",
        "    # Filter & remap labels\n",
        "    subjects = []\n",
        "    for p in bin_paths:\n",
        "        sid = subject_id_from_filename(p)\n",
        "        if sid is None or sid not in full_label_map: continue\n",
        "        lbl = full_label_map[sid]\n",
        "        if lbl in label_keep:\n",
        "            subjects.append((sid, p))\n",
        "    assert subjects, f\"No subjects with labels in {label_keep} found.\"\n",
        "\n",
        "    label_map = {sid: label_remap[full_label_map[sid]] for sid, _ in subjects}\n",
        "\n",
        "    # Build per-subject packs (selected tasks only)\n",
        "    packs = build_per_subject_taskpack(subjects, label_map, task_set)\n",
        "\n",
        "    # Convert to arrays for CV split (subject-level, stratified by label)\n",
        "    y_all = np.array([p[\"y\"] for p in packs], dtype=int)\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "\n",
        "    # HPs for Transformer\n",
        "    hps = best_hps_for(model_name, scenario_substr=hp_scenario_substr)\n",
        "    if (model_name == \"Transformer\") and (scenario_name == \"pd_vs_dd\"):\n",
        "        hps = {**hps, \"d_model\": hps.get(\"d_model\", 128), \"nhead\": hps.get(\"nhead\", 4),\n",
        "              \"num_layers\": max(4, hps.get(\"num_layers\", 3)), \"dropout\": max(0.20, hps.get(\"dropout\", 0.1))}\n",
        "    print(\"[HPs]\", scenario_name, model_name + \":\", hps)\n",
        "\n",
        "     # choose the right model builder\n",
        "    builders = {\n",
        "        \"Transformer\":   lambda: build_model_transformer(hps, modality=\"movement_only\"),\n",
        "        \"CA_LSTM_FCN\":   lambda: build_model_ca_lstm_fcn(hps, modality=\"movement_only\"),\n",
        "    }\n",
        "\n",
        "    fold_ba_scores = []\n",
        "    fold_acc_scores = []\n",
        "    fold_prec_scores, fold_rec_scores, fold_f1_scores = [], [], []\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(y_all)), y_all), start=1):\n",
        "        # build train/val subject lists\n",
        "        train_packs = [packs[i] for i in train_idx]\n",
        "        val_packs   = [packs[i] for i in val_idx]\n",
        "\n",
        "        # standardize movement per fold (fit on ALL train samples across tasks)\n",
        "        # we do per-channel standardization.\n",
        "        # gather all train arrays\n",
        "        all_train = []\n",
        "        for sp in train_packs:\n",
        "            for t, X in sp[\"tasks\"].items():\n",
        "                all_train.append(X)\n",
        "        all_train = np.stack(all_train, axis=0)  # [M, T, C]\n",
        "        scaler = StandardScaler().fit(all_train.reshape(-1, all_train.shape[-1]))\n",
        "\n",
        "        # apply scaler (in-place transform copies)\n",
        "        def _apply_scaler(packs_list):\n",
        "            out = []\n",
        "            for sp in packs_list:\n",
        "                new_tasks = {}\n",
        "                for t, X in sp[\"tasks\"].items():\n",
        "                    Xs = scaler.transform(X)  # [T,C]\n",
        "                    new_tasks[t] = Xs.astype(np.float32)\n",
        "                out.append({\"sid\": sp[\"sid\"], \"y\": sp[\"y\"], \"tasks\": new_tasks})\n",
        "            return out\n",
        "\n",
        "        train_packs_s = _apply_scaler(train_packs)\n",
        "        val_packs_s   = _apply_scaler(val_packs)\n",
        "\n",
        "        # -------- Datasets / Loaders --------\n",
        "        # ----- choose task list for the dataset -----\n",
        "        eval_task_list = [\"ALL\"] if EXPERIMENT_MODE == \"full_132\" else task_set\n",
        "\n",
        "        # ----- augmentation selection -----\n",
        "        aug_for_train = OnTheFlyAugmentation(\n",
        "            rot_p=0.25 if scenario_name == \"pd_vs_dd\" else 0.35,\n",
        "            rot_deg=5   if scenario_name == \"pd_vs_dd\" else 8,\n",
        "            warp_p=0.0\n",
        "        )\n",
        "        aug_prob = 0.30 if scenario_name == \"pd_vs_dd\" else 0.35\n",
        "\n",
        "\n",
        "        train_ds = MultiTaskDataset(\n",
        "            train_packs_s, task_list=eval_task_list, sample_one_task=True,\n",
        "            augmentor=aug_for_train, is_training=True, aug_prob=aug_prob\n",
        "        )\n",
        "        val_ds = MultiTaskDataset(\n",
        "            val_packs_s, task_list=eval_task_list, sample_one_task=False,\n",
        "            augmentor=None, is_training=False\n",
        "        )\n",
        "\n",
        "        bs = 8 if (model_name == \"Transformer\" and EXPERIMENT_MODE == \"full_132\") else 16\n",
        "        g = torch.Generator(); g.manual_seed(SEED)\n",
        "        train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, drop_last=False, generator=g)\n",
        "        val_loader   = DataLoader(val_ds,   batch_size=bs, shuffle=False, drop_last=False)\n",
        "\n",
        "        # Build model & trainer\n",
        "        model = builders[model_name]()\n",
        "\n",
        "        class_w = make_class_weights(np.array([p[\"y\"] for p in train_packs_s], dtype=int), num_classes=2)\n",
        "\n",
        "        trainer = LateFusionTrainer(device=device, class_weights=class_w, label_smoothing=0.05,\n",
        "                                  lr=5e-4)\n",
        "\n",
        "        epochs = SCENARIO_EPOCHS.get(scenario_name, MAX_EPOCHS)\n",
        "        num_tasks_for_log = 1 if EXPERIMENT_MODE == \"full_132\" else len(task_set)\n",
        "\n",
        "        print(f\"\\n=== [{scenario_name}] TaskFusion[{num_tasks_for_log}] — {model_name} : \"\n",
        "              f\"Fold {fold_idx}/5, epochs={epochs} ===\")\n",
        "\n",
        "        best_ba, best_acc, best_prec, best_rec, best_f1 = trainer.train_single_fold(\n",
        "            model, train_loader, val_loader, max_epochs=epochs, fold_num=fold_idx\n",
        "        )\n",
        "        fold_ba_scores.append(float(best_ba))\n",
        "        fold_acc_scores.append(float(best_acc))\n",
        "        fold_prec_scores.append(float(best_prec))\n",
        "        fold_rec_scores.append(float(best_rec))\n",
        "        fold_f1_scores.append(float(best_f1))\n",
        "\n",
        "        # save the best FP32 checkpoint for this fold\n",
        "        ckpt_path = os.path.join(\n",
        "            RESULTS_DIR,\n",
        "            f\"ckpt_{scenario_name}_{_sensor_label_for_results()}_{_clean_name(model_name)}_{task_tag}_fold{fold_idx}.pth\"\n",
        "        )\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        print(f\"[ckpt] Saved best FP32 weights -> {ckpt_path}\")\n",
        "\n",
        "        del model\n",
        "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    # aggregate both metrics\n",
        "    mean_ba  = float(np.mean(fold_ba_scores));  std_ba  = float(np.std(fold_ba_scores,  ddof=1))\n",
        "    mean_acc = float(np.mean(fold_acc_scores)); std_acc = float(np.std(fold_acc_scores, ddof=1))\n",
        "    mean_prec = float(np.mean(fold_prec_scores)); std_prec = float(np.std(fold_prec_scores, ddof=1))\n",
        "    mean_rec  = float(np.mean(fold_rec_scores)); std_rec = float(np.std(fold_rec_scores,  ddof=1))\n",
        "    mean_f1   = float(np.mean(fold_f1_scores)); std_f1 = float(np.std(fold_f1_scores,   ddof=1))\n",
        "\n",
        "    num_tasks_meta = 1 if EXPERIMENT_MODE == \"full_132\" else len(task_set)\n",
        "    print(\n",
        "        f\">>> [{scenario_name}] TaskFusion[{num_tasks_meta}] — {model_name}:\"\n",
        "        f\" BA={mean_ba:.3f}±{std_ba:.3f} | Acc={mean_acc:.3f}±{std_acc:.3f}\"\n",
        "        f\" | Prec={mean_prec:.3f}±{std_prec:.3f} | Rec={mean_rec:.3f}±{std_rec:.3f} | F1={mean_f1:.3f}±{std_f1:.3f}\\n\"\n",
        "        f\"    BA per-fold={np.round(fold_ba_scores,3).tolist()}, Acc per-fold={np.round(fold_acc_scores,3).tolist()}\"\n",
        "    )\n",
        "\n",
        "    out_csv = os.path.join(\n",
        "        RESULTS_DIR,\n",
        "        f\"subjectfusion_{scenario_name}_{sensor_label}_{_clean_name(model_name)}_{task_tag}.csv\"\n",
        "    )\n",
        "\n",
        "    num_tasks_meta = 1 if EXPERIMENT_MODE == \"full_132\" else len(task_set)\n",
        "    # single-row CSV with both BA and Acc\n",
        "    df_out = pd.DataFrame([{\n",
        "        \"Scenario\": scenario_name,\n",
        "        \"TaskSet\": task_tag,\n",
        "        \"NumTasks\": num_tasks_meta,\n",
        "        \"Sensor\": sensor_label,\n",
        "        \"Model\": model_name,\n",
        "        \"Val Balanced Acc (mean)\": mean_ba,\n",
        "        \"Val Balanced Acc (std)\": std_ba,\n",
        "        \"Val Accuracy (mean)\": mean_acc,\n",
        "        \"Val Accuracy (std)\": std_acc,\n",
        "        \"Val Precision (mean)\": mean_prec,\n",
        "        \"Val Precision (std)\": std_prec,\n",
        "        \"Val Recall (mean)\": mean_rec,\n",
        "        \"Val Recall (std)\": std_rec,\n",
        "        \"Val F1 (mean)\": mean_f1,\n",
        "        \"Val F1 (std)\": std_f1,\n",
        "        \"Per-fold BalAcc\": fold_ba_scores,\n",
        "        \"Per-fold Acc\": fold_acc_scores,\n",
        "        \"Per-fold Precision\": fold_prec_scores,\n",
        "        \"Per-fold Recall\": fold_rec_scores,\n",
        "        \"Per-fold F1\": fold_f1_scores,\n",
        "        \"N subjects\": int(len(packs))\n",
        "    }])\n",
        "\n",
        "    df_out.to_csv(out_csv, index=False)\n",
        "    print(f\"Saved final results to: {out_csv}\")\n",
        "    return df_out\n",
        "\n",
        "\n",
        "# ===================== RUNS =====================\n",
        "# 1) PD vs HC with BEST tasks\n",
        "# df_hc_best = run_scenario_latefusion(\n",
        "#     scenario_name=\"pd_vs_hc\",\n",
        "#     label_keep={0,1},\n",
        "#     label_remap={0:0, 1:1},\n",
        "#     hp_scenario_substr=\"pd_vs_hc\",\n",
        "#     task_set=FOCUS_TASKS,\n",
        "#     model_name=\"CA_LSTM_FCN\"\n",
        "# )\n",
        "\n",
        "# 2) PD vs HC with ALL tasks\n",
        "df_hc_all = run_scenario_latefusion(\n",
        "    scenario_name=\"pd_vs_hc\",\n",
        "    label_keep={0,1},\n",
        "    label_remap={0:0, 1:1},\n",
        "    hp_scenario_substr=\"pd_vs_hc\",\n",
        "    task_set=TASKS,\n",
        "    model_name=\"Transformer\"\n",
        ")\n",
        "\n",
        "# 3) PD vs DD with BEST tasks\n",
        "# df_dd_best = run_scenario_latefusion(\n",
        "#     scenario_name=\"pd_vs_dd\",\n",
        "#     label_keep={1,2},\n",
        "#     label_remap={1:1, 2:0},\n",
        "#     hp_scenario_substr=\"pd_vs_dd|pd_vs_omd\",\n",
        "#     task_set=FOCUS_TASKS,\n",
        "#     model_name=\"CA_LSTM_FCN\"\n",
        "# )\n",
        "\n",
        "# 4) PD vs DD with ALL tasks\n",
        "df_dd_all = run_scenario_latefusion(\n",
        "    scenario_name=\"pd_vs_dd\",\n",
        "    label_keep={1,2},\n",
        "    label_remap={1:1, 2:0},\n",
        "    hp_scenario_substr=\"pd_vs_dd|pd_vs_omd\",\n",
        "    task_set=TASKS,\n",
        "    model_name=\"Transformer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdiT1RjJ6GzR"
      },
      "source": [
        "### Transformer Model Quantization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ONNX dynamic quant (movement-only Transformer) ===\n",
        "ckpts = glob.glob(os.path.join(RESULTS_DIR, \"ckpt_pd_vs_*_fold*.pth\"))\n",
        "print(\"Found ckpts:\", len(ckpts))\n",
        "assert len(ckpts) >= 10, \"Expected ckpt files missing. Run training first.\"\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "EXPERIMENT_MODE = \"acc_gyro_both_wrists\" #all sensors, all wrists, all tasks (use this mode as a default)\n",
        "\n",
        "def strip_value_info(onnx_path: str):\n",
        "    m = onnx.load(onnx_path)\n",
        "    del m.graph.value_info[:]\n",
        "    for n in m.graph.node:\n",
        "        n.doc_string = \"\"\n",
        "    onnx.save(m, onnx_path)\n",
        "\n",
        "def _mode_input_channels():\n",
        "    return 12 if EXPERIMENT_MODE==\"acc_gyro_both_wrists\" else (6 if EXPERIMENT_MODE==\"acc_only_both_wrists\" else 132)\n",
        "\n",
        "def _sensor_label_for_results():\n",
        "    return {\n",
        "        \"acc_gyro_both_wrists\": \"Accel+GyroBothWrists\",\n",
        "        \"acc_only_both_wrists\": \"AccelerometerBothWrists\",\n",
        "        \"full_132\": \"AllTasks_AllSensors_BothWrists_132ch\",\n",
        "    }[EXPERIMENT_MODE]\n",
        "\n",
        "def sizeof_mb(path):\n",
        "    return os.path.getsize(path) / (1024*1024)\n",
        "\n",
        "class _ExportWrapper(nn.Module):\n",
        "    def __init__(self, model): super().__init__(); self.model = model.eval()\n",
        "    def forward(self, movement_data): return self.model(movement_data, None)\n",
        "\n",
        "def export_onnx_1input(model, onnx_path, T, C, opset=18):\n",
        "    wrapper = _ExportWrapper(copy.deepcopy(model).to(\"cpu\").eval())\n",
        "\n",
        "    dummy = torch.randn(1, T, C, dtype=torch.float32)\n",
        "\n",
        "    torch.onnx.export(\n",
        "        wrapper,\n",
        "        dummy,\n",
        "        onnx_path,\n",
        "        input_names=[\"movement_data\"],\n",
        "        output_names=[\"logits\"],\n",
        "        opset_version=opset,\n",
        "        do_constant_folding=True,\n",
        "    )\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import inspect\n",
        "print(inspect.signature(quantize_dynamic))\n",
        "\n",
        "def quantize_onnx_dynamic(fp32_path, int8_path):\n",
        "    quantize_dynamic(\n",
        "        model_input=fp32_path,\n",
        "        model_output=int8_path,\n",
        "        op_types_to_quantize=[\"MatMul\",\"Gemm\"],\n",
        "        per_channel=True,\n",
        "        reduce_range=False,\n",
        "        weight_type=QuantType.QInt8,\n",
        "        extra_options={\"DisableShapeInference\": True},\n",
        "    )\n",
        "    print(\"[quant] DisableShapeInference=True\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_bal_acc_onnx(sess, val_ds):\n",
        "    inp = sess.get_inputs()[0].name\n",
        "    y_true, y_pred = [], []\n",
        "    for x_stack, task_mask, y in DataLoader(val_ds, batch_size=1, shuffle=False):\n",
        "        K = x_stack.shape[1]\n",
        "        outs = []\n",
        "        for k in range(K):\n",
        "            if task_mask[:, k].sum().item() == 0: continue\n",
        "            xk = x_stack[:, k, :, :].numpy().astype(np.float32)\n",
        "            outs.append(sess.run(None, {inp: xk})[0])      # [1,C]\n",
        "        if not outs: continue\n",
        "        lt = np.concatenate([o[:,None,:] for o in outs], 1)  # [1,K',C]\n",
        "        gate = lt.mean(-1); att = np.exp(gate - gate.max(1, keepdims=True))\n",
        "        att /= att.sum(1, keepdims=True)\n",
        "        fused = (lt * att[..., None]).sum(1)  # [1,C]\n",
        "        y_pred.append(int(fused.argmax(-1)[0])); y_true.append(int(y.item()))\n",
        "    return balanced_accuracy_score(np.array(y_true), np.array(y_pred))\n",
        "\n",
        "@torch.no_grad()\n",
        "def bench_latency_ms_onnx(sess, val_ds, warmup=3, iters=30):\n",
        "    inp = sess.get_inputs()[0].name\n",
        "    x_stack, task_mask, _ = next(iter(DataLoader(val_ds, batch_size=1, shuffle=False)))\n",
        "    K = x_stack.shape[1]\n",
        "    for _ in range(max(0,warmup)):\n",
        "        for k in range(K):\n",
        "            if task_mask[:,k].sum()==0: continue\n",
        "            _ = sess.run(None, {inp: x_stack[:,k,:,:].numpy().astype(np.float32)})\n",
        "    t0 = time.perf_counter()\n",
        "    for _ in range(max(1,iters)):\n",
        "        for k in range(K):\n",
        "            if task_mask[:,k].sum()==0: continue\n",
        "            _ = sess.run(None, {inp: x_stack[:,k,:,:].numpy().astype(np.float32)})\n",
        "    return (time.perf_counter()-t0)*1000/max(1,iters)\n",
        "\n",
        "def build_val_dataset_for_fold(subjects, label_map, task_set, fold_idx, n_splits=5):\n",
        "    packs = build_per_subject_taskpack(subjects, label_map, task_set)\n",
        "    y_all = np.array([p[\"y\"] for p in packs], dtype=int)\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    train_idx, val_idx = list(skf.split(np.zeros(len(y_all)), y_all))[fold_idx-1]\n",
        "    train_packs = [packs[i] for i in train_idx]; val_packs = [packs[i] for i in val_idx]\n",
        "    # fit scaler on all train arrays\n",
        "    all_train = np.stack([X for sp in train_packs for X in sp[\"tasks\"].values()], axis=0)\n",
        "    scaler = StandardScaler().fit(all_train.reshape(-1, all_train.shape[-1]))\n",
        "    def _apply(packs):\n",
        "        out = []\n",
        "        for sp in packs:\n",
        "            ts = {t: scaler.transform(X).astype(np.float32) for t, X in sp[\"tasks\"].items()}\n",
        "            out.append({\"sid\": sp[\"sid\"], \"y\": sp[\"y\"], \"tasks\": ts})\n",
        "        return out\n",
        "    train_s, val_s = _apply(train_packs), _apply(val_packs)\n",
        "    eval_tasks = [\"ALL\"] if EXPERIMENT_MODE==\"full_132\" else task_set\n",
        "    val_ds = MultiTaskDataset(val_s, task_list=eval_tasks, sample_one_task=False, augmentor=None, is_training=False)\n",
        "    return val_ds, len(packs)\n",
        "\n",
        "def run_quant_for_model_onnx(scenario_name, label_keep, label_remap, task_set):\n",
        "    print(f\"\\n=== Quantization (ONNX): Transformer — {scenario_name} — mode={EXPERIMENT_MODE} ===\")\n",
        "    # subjects\n",
        "    full_map = load_full_label_map()\n",
        "    subs = []\n",
        "    for p in sorted(glob.glob(os.path.join(MOVEMENT_DIR, \"*.bin\"))):\n",
        "        sid = subject_id_from_filename(p)\n",
        "        if sid is not None and sid in full_map and full_map[sid] in label_keep:\n",
        "            subs.append((sid, p))\n",
        "    assert subs, f\"No subjects for {scenario_name}\"\n",
        "    label_map = {sid: label_remap[full_map[sid]] for sid,_ in subs}\n",
        "\n",
        "    sensor = _sensor_label_for_results()\n",
        "    # Keep filenames consistent with training for full_132\n",
        "    if EXPERIMENT_MODE == \"full_132\":\n",
        "        task_tag = \"alltasks\"\n",
        "    else:\n",
        "        task_tag = \"alltasks\" if set(task_set) == set(TASKS) else f\"{len(task_set)}tasks\"\n",
        "\n",
        "    rows = []; C = _mode_input_channels()\n",
        "\n",
        "    for fold_idx in range(1,6):\n",
        "        val_ds, n_subj = build_val_dataset_for_fold(subs, label_map, task_set, fold_idx)\n",
        "        # rebuild model + load state\n",
        "        try:\n",
        "            hps = best_hps_for(\"Transformer\", scenario_substr=(\"pd_vs_dd|pd_vs_omd\" if scenario_name==\"pd_vs_dd\" else \"pd_vs_hc\"))\n",
        "        except Exception:\n",
        "            hps = {}\n",
        "        if scenario_name == \"pd_vs_dd\":\n",
        "            hps = {**hps, \"d_model\": hps.get(\"d_model\", 128), \"nhead\": hps.get(\"nhead\", 4),\n",
        "                   \"num_layers\": max(4, hps.get(\"num_layers\", 3)), \"dropout\": max(0.20, hps.get(\"dropout\", 0.1))}\n",
        "        model = build_model_transformer(hps, modality=\"movement_only\")\n",
        "        ckpt = os.path.join(RESULTS_DIR, f\"ckpt_{scenario_name}_{sensor}_{_clean_name('Transformer')}_{task_tag}_fold{fold_idx}.pth\")\n",
        "        state = torch.load(ckpt, map_location=\"cpu\"); model.load_state_dict(state, strict=True); model.eval()\n",
        "\n",
        "        # export & quantize\n",
        "        onnx_fp32 = os.path.join(RESULTS_DIR, f\"onnx_{scenario_name}_{sensor}_Transformer_{task_tag}_fold{fold_idx}.onnx\")\n",
        "        export_onnx_1input(model, onnx_fp32, T=TARGET_T, C=C)\n",
        "        # remove conflicting shape metadata before quantization\n",
        "        strip_value_info(onnx_fp32)\n",
        "        onnx_int8 = onnx_fp32.replace(\".onnx\", \"_int8.onnx\")\n",
        "        quantize_onnx_dynamic(onnx_fp32, onnx_int8)\n",
        "\n",
        "        # run ORT\n",
        "        s_fp32 = ort.InferenceSession(onnx_fp32, providers=[\"CPUExecutionProvider\"])\n",
        "        s_int8 = ort.InferenceSession(onnx_int8, providers=[\"CPUExecutionProvider\"])\n",
        "        ba_f  = eval_bal_acc_onnx(s_fp32, val_ds); lat_f  = bench_latency_ms_onnx(s_fp32, val_ds)\n",
        "        ba_q  = eval_bal_acc_onnx(s_int8, val_ds); lat_q  = bench_latency_ms_onnx(s_int8, val_ds)\n",
        "        sz_f, sz_q = sizeof_mb(onnx_fp32), sizeof_mb(onnx_int8)\n",
        "\n",
        "        print(f\"  Fold {fold_idx}: BA {ba_f:.3f}→{ba_q:.3f} | ms {lat_f:.2f}→{lat_q:.2f} | MB {sz_f:.1f}→{sz_q:.1f}\")\n",
        "        rows.append({\n",
        "            \"Scenario\": scenario_name, \"Model\": \"Transformer\", \"Mode\": EXPERIMENT_MODE, \"Fold\": fold_idx,\n",
        "            \"Quant Strategy\": \"ONNX dynamic (MatMul/Gemm)\", \"N subjects\": int(n_subj),\n",
        "            \"BA FP32\": float(ba_f), \"BA INT8\": float(ba_q), \"Δ BA\": float(ba_q - ba_f),\n",
        "            \"Latency FP32 (ms)\": float(lat_f), \"Latency INT8 (ms)\": float(lat_q),\n",
        "            \"Latency Δ% (↓=faster)\": float(100.0*(lat_f - lat_q)/max(lat_f,1e-8)),\n",
        "            \"Size FP32 (MB)\": float(sz_f), \"Size INT8 (MB)\": float(sz_q)\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    out_csv = os.path.join(RESULTS_DIR, f\"quant_report_{scenario_name}_{sensor}_Transformer_{task_tag}_onnx.csv\")\n",
        "    df.to_csv(out_csv, index=False); print(f\"[saved] {out_csv}\")\n",
        "    return df\n",
        "\n",
        "# ---- Run both scenarios ----\n",
        "SCENARIOS = [\n",
        "    dict(name=\"pd_vs_hc\", keep={0,1}, remap={0:0, 1:1}),\n",
        "    dict(name=\"pd_vs_dd\", keep={1,2}, remap={1:1, 2:0}),\n",
        "]\n",
        "if EXPERIMENT_MODE == \"full_132\":\n",
        "    TASK_SET = TASKS\n",
        "else:\n",
        "    TASK_SET = TASKS if EXPERIMENT_MODE in (\"acc_gyro_both_wrists\", \"acc_only_both_wrists\") else [\"ALL\"]\n",
        "\n",
        "for sc in SCENARIOS:\n",
        "    run_quant_for_model_onnx(sc[\"name\"], sc[\"keep\"], sc[\"remap\"], TASK_SET)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "sz8T2fXKfrqU",
        "outputId": "d88656ef-eb06-42e6-fcb3-66efd85260cc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found ckpts: 20\n",
            "(model_input: 'str | Path | onnx.ModelProto', model_output: 'str | Path', op_types_to_quantize=None, per_channel=False, reduce_range=False, weight_type=<QuantType.QInt8: 0>, nodes_to_quantize=None, nodes_to_exclude=None, use_external_data_format=False, extra_options=None)\n",
            "\n",
            "=== Quantization (ONNX): Transformer — pd_vs_hc — mode=acc_gyro_both_wrists ===\n",
            "[info] Loaded label map for 469 subjects.\n",
            "[torch.onnx] Obtain model graph for `_ExportWrapper([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `_ExportWrapper([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 2 of general pattern rewrite rules.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[quant] DisableShapeInference=True\n",
            "  Fold 1: BA 0.820→0.762 | ms 211.31→164.16 | MB 7.3→2.7\n",
            "[torch.onnx] Obtain model graph for `_ExportWrapper([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `_ExportWrapper([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 2 of general pattern rewrite rules.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[quant] DisableShapeInference=True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1822394984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSCENARIOS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mrun_quant_for_model_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"keep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"remap\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTASK_SET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1822394984.py\u001b[0m in \u001b[0;36mrun_quant_for_model_onnx\u001b[0;34m(scenario_name, label_keep, label_remap, task_set)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0ms_fp32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CPUExecutionProvider\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0ms_int8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_int8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CPUExecutionProvider\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mba_f\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0meval_bal_acc_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlat_f\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbench_latency_ms_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fp32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mba_q\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0meval_bal_acc_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_int8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlat_q\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mbench_latency_ms_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_int8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0msz_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msizeof_mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_fp32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizeof_mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_int8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1822394984.py\u001b[0m in \u001b[0;36meval_bal_acc_onnx\u001b[0;34m(sess, val_ds)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtask_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mxk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# [1,C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [1,K',C]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_meta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPFail\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}